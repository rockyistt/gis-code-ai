{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rockyistt/gis-code-ai/blob/main/notebooks/Train_GIS_Model_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Disable optional backends to prevent import conflicts (PyTorch-only training)\n",
        "import os\n",
        "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
        "os.environ[\"TRANSFORMERS_NO_FLAX\"] = \"1\"\n",
        "os.environ[\"TRANSFORMERS_NO_TORCHVISION\"] = \"1\"\n",
        "os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"\n",
        "print(\"‚úÖ Env set: disabled TF/FLAX/TORCHVISION for transformers.\")"
      ],
      "metadata": {
        "id": "oeB5NXZ-CMpB",
        "outputId": "d7049239-eb86-4284-f073-15d475ebadeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "oeB5NXZ-CMpB",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Env set: disabled TF/FLAX/TORCHVISION for transformers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33fe0c37",
      "metadata": {
        "id": "33fe0c37"
      },
      "source": [
        "# üöÄ GIS‰ª£Á†ÅÁîüÊàêÊ®°ÂûãËÆ≠ÁªÉ - Google Colab (CodeLlama)\n",
        "\n",
        "Êú¨NotebookÂú®Google Colab‰∏äËÆ≠ÁªÉGIS‰ª£Á†ÅÁîüÊàêÊ®°ÂûãÔºà**Êñá‰ª∂Á∫ß + CodeLlama**Ôºâ\n",
        "\n",
        "**Êñá‰ª∂Á∫ßËÆ≠ÁªÉ** - Ê®°ÂûãÂ≠¶‰π†ÁîüÊàêÂÆåÊï¥ÁöÑÂ∑•‰ΩúÊµÅËÄå‰∏çÊòØÂçï‰∏™Ê≠•È™§\n",
        "- ËæìÂÖ•ÔºöÁî®Êà∑ÁöÑÈ´òÂ±ÇÊåá‰ª§ÔºàËã±ËØ≠/Ëç∑ÂÖ∞ËØ≠ÔºåÂ¶ÇÔºö\"Create MS and HS cable objects\"Ôºâ\n",
        "- ËæìÂá∫ÔºöÂÆåÊï¥ÁöÑÂ∑•‰ΩúÊµÅJSON‰ª£Á†ÅÔºàÂåÖÂê´ÊâÄÊúâÊìç‰ΩúÊ≠•È™§Ôºâ\n",
        "- ‰ºòÂäøÔºö‰∏ÄÊ¨°Êé®ÁêÜÁîüÊàêÊï¥‰∏™ÊµãËØïËÑöÊú¨\n",
        "- **Ê®°Âûã**ÔºöCodeLlama-7B-InstructÔºà‰∏ì‰∏∫‰ª£Á†ÅÁîüÊàê‰ºòÂåñÔºâ\n",
        "\n",
        "**‰ΩøÁî®ÂâçÂáÜÂ§áÔºö**\n",
        "1. ËøêË°åÁéØÂ¢ÉÔºö`Runtime > Change runtime type > T4 GPU`ÔºàÂÖçË¥πÔºâÊàñ `A100 GPU`ÔºàColab ProÔºâ\n",
        "2. Êï∞ÊçÆÂáÜÂ§áÔºöÁ°Æ‰øùÂ∑≤ÁîüÊàêËÆ≠ÁªÉÊï∞ÊçÆÊñá‰ª∂\n",
        "3. È¢ÑËÆ°Êó∂Èó¥Ôºö4-6Â∞èÊó∂ÔºàT4Ôºâ/ 1-2Â∞èÊó∂ÔºàA100Ôºâ\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "130ae856",
      "metadata": {
        "id": "130ae856"
      },
      "source": [
        "## üìã Ê≠•È™§1ÔºöÁéØÂ¢ÉËÆæÁΩÆ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "859e1522",
      "metadata": {
        "id": "859e1522",
        "outputId": "966c3872-af75-4d97-8e67-5895faf675e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jan 14 14:58:59 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P8             12W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Ê£ÄÊü•GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8d621428",
      "metadata": {
        "id": "8d621428",
        "outputId": "aa5e1470-95aa-4b5f-e25d-7427b5888fac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Installing dependencies...\n",
            "‚úÖ Core dependencies installed!\n"
          ]
        }
      ],
      "source": [
        "# ÂÆâË£Ö‰æùËµñÔºàÁ∫¶3-5ÂàÜÈíüÔºâ\n",
        "print(\"üì¶ Installing dependencies...\")\n",
        "\n",
        "# ÂÖàÈîÅÂÆöÂÖ≥ÈîÆÂü∫Á°ÄÂåÖÔºàÈÅøÂÖçËá™Âä®ÂçáÁ∫ßÔºâ\n",
        "!pip install -q torch==2.9.0 --no-deps\n",
        "!pip install -q fsspec==2024.3.1\n",
        "!pip install -q numpy==2.0.2 --no-deps\n",
        "\n",
        "# ÂÆâË£Ö‰∏ªË¶ÅËÆ≠ÁªÉÂ∫ìÔºàÊåáÂÆöÂÖºÂÆπÁâàÊú¨Ôºâ\n",
        "!pip install -q transformers==4.46.0\n",
        "!pip install -q peft==0.13.0\n",
        "!pip install -q datasets==2.19.0\n",
        "!pip install -q \"accelerate>=1.0.0\"\n",
        "!pip install -q sentencepiece==0.2.0\n",
        "!pip install -q tqdm\n",
        "!pip install -q huggingface-hub==0.26.0\n",
        "\n",
        "print(\"‚úÖ Core dependencies installed! If running in Colab, restart runtime after this cell.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torchvision"
      ],
      "metadata": {
        "id": "Ntp_pEd3DF9n"
      },
      "id": "Ntp_pEd3DF9n",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "62236c8b",
      "metadata": {
        "id": "62236c8b"
      },
      "source": [
        "## üíæ Ê≠•È™§2ÔºöÊåÇËΩΩGoogle DriveÔºà‰øùÂ≠òÊ®°ÂûãÔºâ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6b086f8d",
      "metadata": {
        "id": "6b086f8d",
        "outputId": "f083c010-accd-475b-e872-d583ee5458a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Google Drive mounted!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ÂàõÂª∫ËæìÂá∫ÁõÆÂΩï\n",
        "!mkdir -p /content/drive/MyDrive/gis-models\n",
        "print(\"‚úÖ Google Drive mounted!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "752feee6",
      "metadata": {
        "id": "752feee6"
      },
      "source": [
        "## üìÇ Ê≠•È™§3Ôºö‰∏ä‰º†Êï∞ÊçÆ\n",
        "\n",
        "**‰∏§ÁßçÊñπÂºè‰ªªÈÄâÂÖ∂‰∏ÄÔºö**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5240de6f",
      "metadata": {
        "id": "5240de6f"
      },
      "source": [
        "### ÊñπÂºèAÔºö‰ªéGitHubÂÖãÈöÜ‰ªìÂ∫ìÔºàÊé®ËçêÔºâ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7ff6558e",
      "metadata": {
        "id": "7ff6558e",
        "outputId": "fd195fc3-c5d5-4e7c-ef0c-9d910185a04b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìç Current directory: /content\n",
            "‚úÖ Repository already exists at /content/gis-code-ai\n",
            "üìç Working directory: /content/gis-code-ai\n",
            "\n",
            "üìã Checking data files...\n",
            "‚úÖ data/processed/file_level_instructions_weighted_variants_marked.jsonl (2.1 MB)\n",
            "‚úÖ data/processed/parsed_workflows.jsonl (13.8 MB)\n",
            "\n",
            "üéâ All data files ready! Ready to proceed with data preparation\n"
          ]
        }
      ],
      "source": [
        "# ÂÖãÈöÜ‰ªìÂ∫ìÂà∞ÂΩìÂâçÁõÆÂΩï\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "print(\"üìç Current directory:\", os.getcwd())\n",
        "\n",
        "# Ê£ÄÊü•ÊòØÂê¶Â∑≤ÂÖãÈöÜ\n",
        "if os.path.exists('/content/gis-code-ai'):\n",
        "    print(\"‚úÖ Repository already exists at /content/gis-code-ai\")\n",
        "    os.chdir('/content/gis-code-ai')\n",
        "elif os.path.exists('gis-code-ai'):\n",
        "    print(\"‚úÖ Repository already exists locally\")\n",
        "    os.chdir('gis-code-ai')\n",
        "else:\n",
        "    print(\"üîÑ Cloning repository...\")\n",
        "    result = subprocess.run(\n",
        "        ['git', 'clone', 'https://github.com/rockyistt/gis-code-ai.git'],\n",
        "        cwd='/content',\n",
        "        capture_output=True,\n",
        "        text=True\n",
        "    )\n",
        "    if result.returncode == 0:\n",
        "        os.chdir('/content/gis-code-ai')\n",
        "        print(\"‚úÖ Repository cloned successfully\")\n",
        "    else:\n",
        "        print(f\"‚ùå Clone failed: {result.stderr}\")\n",
        "        raise RuntimeError(\"Failed to clone repository\")\n",
        "\n",
        "print(f\"üìç Working directory: {os.getcwd()}\")\n",
        "\n",
        "# Ê£ÄÊü•Êï∞ÊçÆÊñá‰ª∂\n",
        "print(\"\\nüìã Checking data files...\")\n",
        "required_files = [\n",
        "    'data/processed/file_level_instructions_weighted_variants_marked.jsonl',\n",
        "    'data/processed/parsed_workflows.jsonl'\n",
        "]\n",
        "\n",
        "all_exist = True\n",
        "for f in required_files:\n",
        "    if os.path.exists(f):\n",
        "        size_mb = os.path.getsize(f) / (1024*1024)\n",
        "        print(f\"‚úÖ {f} ({size_mb:.1f} MB)\")\n",
        "    else:\n",
        "        print(f\"‚ùå {f}\")\n",
        "        all_exist = False\n",
        "\n",
        "if all_exist:\n",
        "    print(\"\\nüéâ All data files ready! Ready to proceed with data preparation\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Some data files are missing\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23f32dcb",
      "metadata": {
        "id": "23f32dcb"
      },
      "source": [
        "## üîÑ Ê≠•È™§4ÔºöÂáÜÂ§áËÆ≠ÁªÉÊï∞ÊçÆ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a303fdcd",
      "metadata": {
        "id": "a303fdcd",
        "outputId": "0251f6b1-0511-4cbf-b23b-baa448713d4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Data preparation function defined\n"
          ]
        }
      ],
      "source": [
        "# ÂÆö‰πâÊï∞ÊçÆÂáÜÂ§áÂáΩÊï∞ÔºàÁõ¥Êé•Âú®notebook‰∏≠ËøêË°åÔºâ\n",
        "import json\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "def prepare_file_level_training_data(instructions_file, workflows_file, output_dir, max_samples=None, split_ratio=0.9):\n",
        "    \"\"\"ÂáÜÂ§áÊñá‰ª∂Á∫ßËÆ≠ÁªÉÊï∞ÊçÆ\"\"\"\n",
        "\n",
        "    # Ê£ÄÊü•Êñá‰ª∂ÊòØÂê¶Â≠òÂú®\n",
        "    if not os.path.exists(instructions_file):\n",
        "        print(f\"‚ùå Instructions file not found: {instructions_file}\")\n",
        "        print(\"\\nüìÇ Available files in data/processed/:\")\n",
        "        if os.path.exists('data/processed'):\n",
        "            for f in os.listdir('data/processed'):\n",
        "                if os.path.isfile(f'data/processed/{f}'):\n",
        "                    size = os.path.getsize(f'data/processed/{f}') / (1024*1024)\n",
        "                    print(f\"  - {f} ({size:.1f} MB)\")\n",
        "        else:\n",
        "            print(\"  ‚ùå data/processed/ directory not found!\")\n",
        "        return None, None\n",
        "\n",
        "    if not os.path.exists(workflows_file):\n",
        "        print(f\"‚ùå Workflows file not found: {workflows_file}\")\n",
        "        return None, None\n",
        "\n",
        "    print(f\"üìñ Loading file-level instructions from {instructions_file}\")\n",
        "    instructions = {}\n",
        "    with open(instructions_file, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            if line.strip():\n",
        "                item = json.loads(line)\n",
        "                file_id = item.get('file_id', '')\n",
        "                instructions[file_id] = item\n",
        "    print(f\"‚úÖ Loaded {len(instructions)} file-level instructions\")\n",
        "\n",
        "    print(f\"üìñ Loading workflows from {workflows_file}\")\n",
        "    workflows = {}\n",
        "    with open(workflows_file, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            if line.strip():\n",
        "                wf = json.loads(line)\n",
        "                workflows[wf.get('file_id', '')] = wf\n",
        "    print(f\"‚úÖ Loaded {len(workflows)} workflows\")\n",
        "\n",
        "    print(\"üîÑ Converting to training format (file-level)...\")\n",
        "    training_samples = []\n",
        "\n",
        "    count = 0\n",
        "    for file_id, instr in tqdm(instructions.items()):\n",
        "        workflow = workflows.get(file_id, {})\n",
        "\n",
        "        if not workflow:\n",
        "            continue\n",
        "\n",
        "        # Ê∏ÖÁêÜÊåá‰ª§\n",
        "        instruction_text = instr.get('instruction', '').replace('**', '').replace('*', '')\n",
        "        instruction_text = ' '.join(instruction_text.split()).strip()\n",
        "\n",
        "        # ÊûÑÂª∫‰∏ä‰∏ãÊñá\n",
        "        test_app = workflow.get('test_app', '')\n",
        "        database = workflow.get('database', '')\n",
        "        total_steps = workflow.get('total_steps', 0)\n",
        "\n",
        "        context_parts = []\n",
        "        if test_app:\n",
        "            context_parts.append(f\"Application: {test_app}\")\n",
        "        if database:\n",
        "            context_parts.append(f\"Database: {database}\")\n",
        "        if total_steps > 0:\n",
        "            context_parts.append(f\"Steps: {total_steps}\")\n",
        "        input_context = \" | \".join(context_parts)\n",
        "\n",
        "        # ÊèêÂèñÂÆåÊï¥Â∑•‰ΩúÊµÅJSONÔºàÊâÄÊúâstepsÔºâ\n",
        "        steps = workflow.get('steps', [])\n",
        "        if not steps:\n",
        "            continue\n",
        "\n",
        "        workflow_output = {\n",
        "            \"workflow\": {\n",
        "                \"metadata\": {\n",
        "                    \"test_app\": test_app,\n",
        "                    \"database\": database,\n",
        "                    \"total_steps\": len(steps)\n",
        "                },\n",
        "                \"steps\": steps\n",
        "            }\n",
        "        }\n",
        "        output_code = json.dumps(workflow_output, indent=2, ensure_ascii=False)\n",
        "\n",
        "        # Ë¥®ÈáèËøáÊª§\n",
        "        if len(instruction_text.split()) < 5 or output_code == '{}':\n",
        "            continue\n",
        "\n",
        "        training_samples.append({\n",
        "            \"instruction\": instruction_text,\n",
        "            \"input\": input_context,\n",
        "            \"output\": output_code\n",
        "        })\n",
        "\n",
        "        count += 1\n",
        "        if max_samples and count >= max_samples:\n",
        "            break\n",
        "\n",
        "    print(f\"‚úÖ Created {len(training_samples)} training samples\")\n",
        "\n",
        "    if len(training_samples) == 0:\n",
        "        print(\"‚ùå No training samples created! Check your data files.\")\n",
        "        return None, None\n",
        "\n",
        "    # ÂàíÂàÜËÆ≠ÁªÉÈõÜÂíåÈ™åËØÅÈõÜ\n",
        "    split_idx = int(len(training_samples) * split_ratio)\n",
        "    train_data = training_samples[:split_idx]\n",
        "    val_data = training_samples[split_idx:]\n",
        "\n",
        "    print(f\"üìä Split: {len(train_data)} train, {len(val_data)} validation\")\n",
        "\n",
        "    # ‰øùÂ≠ò\n",
        "    output_dir = Path(output_dir)\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    train_file = output_dir / \"training_data_train.json\"\n",
        "    val_file = output_dir / \"training_data_val.json\"\n",
        "\n",
        "    with open(train_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(train_data, f, indent=2, ensure_ascii=False)\n",
        "    print(f\"üíæ Train data saved: {train_file}\")\n",
        "\n",
        "    with open(val_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(val_data, f, indent=2, ensure_ascii=False)\n",
        "    print(f\"üíæ Validation data saved: {val_file}\")\n",
        "\n",
        "    return train_data, val_data\n",
        "\n",
        "print(\"‚úÖ Data preparation function defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3b1b1c77",
      "metadata": {
        "id": "3b1b1c77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6f68458-63b5-4b75-8c82-c6fec2d07cae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "üîÑ ÂºÄÂßãÊï∞ÊçÆÂáÜÂ§á...\n",
            "üìç Working directory: /content/gis-code-ai\n",
            "======================================================================\n",
            "üìñ Loading file-level instructions from data/processed/file_level_instructions_weighted_variants_marked.jsonl\n",
            "‚úÖ Loaded 1012 file-level instructions\n",
            "üìñ Loading workflows from data/processed/parsed_workflows.jsonl\n",
            "‚úÖ Loaded 1012 workflows\n",
            "üîÑ Converting to training format (file-level)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1012/1012 [00:00<00:00, 1446.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Created 1012 training samples\n",
            "üìä Split: 910 train, 102 validation\n",
            "üíæ Train data saved: data/training/training_data_train.json\n",
            "üíæ Validation data saved: data/training/training_data_val.json\n",
            "\n",
            "======================================================================\n",
            "üéâ Êï∞ÊçÆÂáÜÂ§áÂÆåÊàêÔºÅ\n",
            "üìä Êï∞ÊçÆÁ≤íÂ∫¶: Êñá‰ª∂Á∫ßÔºàÂÆåÊï¥Â∑•‰ΩúÊµÅÔºâ\n",
            "üìä ËÆ≠ÁªÉÊ†∑Êú¨: 910\n",
            "üìä È™åËØÅÊ†∑Êú¨: 102\n",
            "======================================================================\n",
            "\n",
            "üìù ËÆ≠ÁªÉÊ†∑Êú¨Á§∫‰æã:\n",
            "Instruction: Workflow: create E MS Kabel, E HS Kabel, E LS Kabel in elektra in NRG Beheerkaart Elektra MS...\n",
            "Input: Application: NRG Beheerkaart Elektra MS | Steps: 7\n",
            "Output preview: {\n",
            "  \"workflow\": {\n",
            "    \"metadata\": {\n",
            "      \"test_app\": \"NRG Beheerkaart Elektra MS\",\n",
            "      \"database\": \"\",\n",
            "      \"total_steps\": 7\n",
            "    },\n",
            "    \"steps\": [\n",
            "      {\n",
            "        \"step_index\": 0,\n",
            "        \"databas...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ËøêË°åÊï∞ÊçÆÂáÜÂ§áÔºàÁõ¥Êé•Ë∞ÉÁî®ÂáΩÊï∞Ôºâ\n",
        "import os\n",
        "\n",
        "# Á°Æ‰øùÂú®Ê≠£Á°ÆÁöÑÁõÆÂΩï\n",
        "if os.path.exists('/content/gis-code-ai'):\n",
        "    os.chdir('/content/gis-code-ai')\n",
        "elif os.path.exists('gis-code-ai'):\n",
        "    os.chdir('gis-code-ai')\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"üîÑ ÂºÄÂßãÊï∞ÊçÆÂáÜÂ§á...\")\n",
        "print(f\"üìç Working directory: {os.getcwd()}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "train_data, val_data = prepare_file_level_training_data(\n",
        "    instructions_file='data/processed/file_level_instructions_weighted_variants_marked.jsonl',\n",
        "    workflows_file='data/processed/parsed_workflows.jsonl',\n",
        "    output_dir='data/training',\n",
        "    max_samples=None,  # ‰ΩøÁî®ÂÖ®ÈÉ®Êï∞ÊçÆÔºåÊîπ‰∏∫Êï¥Êï∞ÂèØÈôêÂà∂Ê†∑Êú¨Êï∞ÔºàÂ¶Ç500Ôºâ\n",
        "    split_ratio=0.9\n",
        ")\n",
        "\n",
        "if train_data is not None:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üéâ Êï∞ÊçÆÂáÜÂ§áÂÆåÊàêÔºÅ\")\n",
        "    print(f\"üìä Êï∞ÊçÆÁ≤íÂ∫¶: Êñá‰ª∂Á∫ßÔºàÂÆåÊï¥Â∑•‰ΩúÊµÅÔºâ\")\n",
        "    print(f\"üìä ËÆ≠ÁªÉÊ†∑Êú¨: {len(train_data):,}\")\n",
        "    print(f\"üìä È™åËØÅÊ†∑Êú¨: {len(val_data):,}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # ÊòæÁ§∫Á§∫‰æã\n",
        "    if train_data:\n",
        "        print(\"\\nüìù ËÆ≠ÁªÉÊ†∑Êú¨Á§∫‰æã:\")\n",
        "        sample = train_data[0]\n",
        "        print(f\"Instruction: {sample['instruction'][:100]}...\")\n",
        "        print(f\"Input: {sample['input']}\")\n",
        "        print(f\"Output preview: {sample['output'][:200]}...\")\n",
        "else:\n",
        "    print(\"\\n‚ùå Êï∞ÊçÆÂáÜÂ§áÂ§±Ë¥•ÔºÅËØ∑Ê£ÄÊü•‰∏äÈù¢ÁöÑÈîôËØØ‰ø°ÊÅØ„ÄÇ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e032229f",
      "metadata": {
        "id": "e032229f"
      },
      "source": [
        "## üöÄ Ê≠•È™§5ÔºöÂºÄÂßãËÆ≠ÁªÉ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6a171cf7",
      "metadata": {
        "id": "6a171cf7",
        "outputId": "3c76ebf1-84b2-4f95-f256-33a57ebef720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_dtype.py:106: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
            "  if dtype.type == np.bool:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Failed to import transformers.trainer because of the following error (look up to see its traceback):\nFailed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1763\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1764\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1765\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpackaging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__operators__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/_api/v2/__internal__/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_ctx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontrol_status_ctx\u001b[0m \u001b[0;31m# line: 34\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_convert\u001b[0m \u001b[0;31m# line: 493\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/autograph/core/ag_ctx.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mag_logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_export\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/autograph/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_managers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontrol_dependency_on_returns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0malias_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/autograph/utils/context_managers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_array_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_conversion_registry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/dtypes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mml_dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ml_dtypes/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mml_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finfo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfinfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mml_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iinfo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0miinfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ml_dtypes/_finfo.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=invalid-name,missing-class-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m   \u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ml_dtypes/_finfo.py\u001b[0m in \u001b[0;36mfinfo\u001b[0;34m()\u001b[0m\n\u001b[1;32m    699\u001b[0m   _finfo_cache = {\n\u001b[0;32m--> 700\u001b[0;31m       \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minit_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__func__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=attribute-error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_fn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_finfo_type_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ml_dtypes/_finfo.py\u001b[0m in \u001b[0;36m_float8_e8m0fnu_finfo\u001b[0;34m()\u001b[0m\n\u001b[1;32m    667\u001b[0m     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_machar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Float8E8m0fnuMachArLike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tiny\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m       \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtiny\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat8_e8m0fnu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtiny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/core/getlimits.py\u001b[0m in \u001b[0;36mtiny\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/core/getlimits.py\u001b[0m in \u001b[0;36msmallest_normal\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1763\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1764\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1765\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/integrations/integration_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreTrainedModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTFPreTrainedModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1753\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1754\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1755\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1765\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1766\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   1767\u001b[0m                 \u001b[0;34mf\"Failed to import {self.__name__}.{module_name} because of the following error (look up to see its\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1763\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1764\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1765\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# isort: off\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m from .integrations import (\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mget_reporting_integration_callbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1753\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1754\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1755\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1765\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1766\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   1767\u001b[0m                 \u001b[0;34mf\"Failed to import {self.__name__}.{module_name} because of the following error (look up to see its\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3411704014.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m from transformers import (\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1752\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlaceholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1754\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1755\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1756\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1766\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   1767\u001b[0m                 \u001b[0;34mf\"Failed to import {self.__name__}.{module_name} because of the following error (look up to see its\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1768\u001b[0m                 \u001b[0;34mf\" traceback):\\n{e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.trainer because of the following error (look up to see its traceback):\nFailed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForSeq2Seq\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType\n",
        "from datasets import load_dataset\n",
        "\n",
        "print(\"üîß Setting up training with CodeLlama...\")\n",
        "\n",
        "# ============================================================\n",
        "# ÈÖçÁΩÆÂèÇÊï∞ - CodeLlama (Ëã±ËØ≠/Ëç∑ÂÖ∞ËØ≠‰ª£Á†ÅÁîüÊàê‰ºòÂåñ)\n",
        "# ============================================================\n",
        "\n",
        "MODEL_NAME = \"codellama/CodeLlama-7b-Instruct-hf\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/gis-models/codellama-gis-lora\"  # ‰øùÂ≠òÂà∞Google Drive\n",
        "TRAIN_FILE = \"data/training/training_data_train.json\"\n",
        "VAL_FILE = \"data/training/training_data_val.json\"\n",
        "\n",
        "# ËÆ≠ÁªÉÂèÇÊï∞ÔºàCodeLlama‰ºòÂåñÈÖçÁΩÆ - T4ÂÜÖÂ≠ò‰ºòÂåñÔºâ\n",
        "NUM_EPOCHS = 3\n",
        "BATCH_SIZE = 2  # Reduced from 4 for T4 GPU memory\n",
        "GRADIENT_ACCUMULATION = 2  # ÊúâÊïàbatch = 4 (was 16)\n",
        "LEARNING_RATE = 2e-4  # CodeLlamaÊé®ËçêÂ≠¶‰π†Áéá\n",
        "MAX_LENGTH = 1024  # Reduced from 2048 to save memory\n",
        "\n",
        "# LoRAÂèÇÊï∞Ôºà‰ª£Á†ÅÁîüÊàê‰ªªÂä°‰ºòÂåñÔºâ\n",
        "LORA_R = 64  # ËæÉÂ§ßÁöÑrÂÄºÈÄÇÂêàÂ§çÊùÇ‰ª£Á†ÅÁîüÊàê\n",
        "LORA_ALPHA = 16\n",
        "LORA_DROPOUT = 0.05\n",
        "\n",
        "print(f\"üì¶ Model: {MODEL_NAME}\")\n",
        "print(f\"üíæ Output: {OUTPUT_DIR}\")\n",
        "print(f\"üìä Data: FILE-LEVEL (complete workflows)\")\n",
        "print(f\"üìà Epochs: {NUM_EPOCHS}, Batch: {BATCH_SIZE}, Accumulation: {GRADIENT_ACCUMULATION}, LR: {LEARNING_RATE}\")\n",
        "print(f\"üìÑ Max Length: {MAX_LENGTH}\")\n",
        "print(f\"üéØ Optimized for: T4 GPU (14GB VRAM)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "774b429b",
      "metadata": {
        "id": "774b429b"
      },
      "outputs": [],
      "source": [
        "# Âä†ËΩΩtokenizer (CodeLlama)\n",
        "print(\"üìñ Loading CodeLlama tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    padding_side=\"right\"\n",
        ")\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "print(f\"‚úÖ Tokenizer loaded: vocab_size={len(tokenizer)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚ö†Ô∏è ÂøÖÈ°ªÂú®model loadingÂâçËøêË°åÔºÅÂçáÁ∫ßÂÖ≥ÈîÆÂ∫ì\n",
        "print(\"üîß Upgrading transformers and accelerate...\")\n",
        "\n",
        "# ÂçáÁ∫ßtransformersÂà∞ÂÖºÂÆπÁâàÊú¨\n",
        "!pip install -q --upgrade transformers==4.46.0\n",
        "\n",
        "# ÂçáÁ∫ßaccelerateÂà∞ÊúÄÊñ∞Á®≥ÂÆöÁâà‰øÆÂ§çoptimizer.train()ÈîôËØØ\n",
        "!pip install -q --upgrade accelerate>=1.0.0\n",
        "\n",
        "print(\"‚úÖ Libraries upgraded!\")\n",
        "print(f\"  transformers: 4.46.0\")\n",
        "print(f\"  accelerate: >=1.0.0 (latest stable, fixes optimizer.train() bug)\")\n",
        "print(\"‚ö†Ô∏è IMPORTANT: Runtime restart required!\")\n",
        "print(\"   Please go to: Runtime > Restart runtime\")\n",
        "print(\"   Then re-run all cells in order\")"
      ],
      "metadata": {
        "id": "uqeoQv1HIRN3"
      },
      "id": "uqeoQv1HIRN3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b4deb72",
      "metadata": {
        "id": "7b4deb72"
      },
      "outputs": [],
      "source": [
        "# Á°Æ‰øùÂØºÂÖ•‰∫ÜÂøÖË¶ÅÁöÑÂ∫ì\n",
        "from transformers import AutoModelForCausalLM\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "import torch\n",
        "\n",
        "# Âä†ËΩΩÊ®°ÂûãÔºà‰∏ç‰ΩøÁî®ÈáèÂåñ - ÊúÄÁ®≥ÂÆöÁöÑÊñπÂºèÔºâ\n",
        "print(\"ü§ñ Loading CodeLlama-7B with device offloading...\")\n",
        "\n",
        "# ‰∏ç‰ΩøÁî®BitsAndBytesConfigÔºåÁõ¥Êé•Áî®device_map=\"auto\"\n",
        "# ËøôÊ†∑ÂèØ‰ª•Ëá™Âä®Âú®GPUÂíåCPU‰πãÈó¥Âπ≥Ë°°ÊòæÂ≠ò\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    low_cpu_mem_usage=True\n",
        ")\n",
        "\n",
        "print(\"‚úÖ CodeLlama base model loaded (float16 with device offloading)\")\n",
        "\n",
        "# ÂêØÁî®Ê¢ØÂ∫¶Ê£ÄÊü•ÁÇπÔºàËäÇÁúÅÊòæÂ≠òÔºå‰∏çÈúÄË¶Åprepare_model_for_kbit_trainingÔºâ\n",
        "model.gradient_checkpointing_enable()\n",
        "print(\"‚úÖ Gradient checkpointing enabled\")\n",
        "\n",
        "# Â∫îÁî®LoRA\n",
        "print(\"üîß Applying LoRA...\")\n",
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.CAUSAL_LM,\n",
        "    inference_mode=False,\n",
        "    r=LORA_R,\n",
        "    lora_alpha=LORA_ALPHA,\n",
        "    lora_dropout=LORA_DROPOUT,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    bias=\"none\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "print(\"‚úÖ LoRA applied!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3a6aeaa",
      "metadata": {
        "id": "b3a6aeaa"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# ÂáÜÂ§áÊï∞ÊçÆÈõÜ\n",
        "print(\"üìä Preparing datasets...\")\n",
        "\n",
        "train_data = load_dataset('json', data_files=TRAIN_FILE, split='train')\n",
        "eval_data = load_dataset('json', data_files=VAL_FILE, split='train')\n",
        "\n",
        "print(f\"  Train: {len(train_data)} samples\")\n",
        "print(f\"  Val: {len(eval_data)} samples\")\n",
        "\n",
        "# Ê†ºÂºèÂåñprompt (CodeLlama‰ºòÂåñÊ†ºÂºè)\n",
        "def format_prompt(example):\n",
        "    instruction = example['instruction']\n",
        "    input_text = example.get('input', '')\n",
        "    output = example['output']\n",
        "\n",
        "    # CodeLlamaÊõ¥ÈÄÇÂêàÁõ¥Êé•ÁöÑ‰ª£Á†ÅÁîüÊàêÊ†ºÂºè\n",
        "    if input_text:\n",
        "        prompt = f\"\"\"You are a GIS workflow code generator. Generate complete JSON workflow code based on the instruction.\n",
        "\n",
        "Instruction: {instruction}\n",
        "Context: {input_text}\n",
        "\n",
        "JSON Code:\n",
        "{output}\"\"\"\n",
        "    else:\n",
        "        prompt = f\"\"\"You are a GIS workflow code generator. Generate complete JSON workflow code based on the instruction.\n",
        "\n",
        "Instruction: {instruction}\n",
        "\n",
        "JSON Code:\n",
        "{output}\"\"\"\n",
        "\n",
        "    return {\"text\": prompt}\n",
        "\n",
        "train_data = train_data.map(format_prompt, remove_columns=train_data.column_names)\n",
        "eval_data = eval_data.map(format_prompt, remove_columns=eval_data.column_names)\n",
        "\n",
        "# Tokenize\n",
        "def tokenize_function(examples):\n",
        "    tokenized = tokenizer(\n",
        "        examples['text'],\n",
        "        truncation=True,\n",
        "        max_length=MAX_LENGTH,\n",
        "        padding=False,\n",
        "        return_tensors=None\n",
        "    )\n",
        "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
        "    return tokenized\n",
        "\n",
        "print(\"üîÑ Tokenizing...\")\n",
        "train_dataset = train_data.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=train_data.column_names,\n",
        "    desc=\"Tokenizing train\"\n",
        ")\n",
        "\n",
        "eval_dataset = eval_data.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=eval_data.column_names,\n",
        "    desc=\"Tokenizing val\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Datasets ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "246a2b8b",
      "metadata": {
        "id": "246a2b8b"
      },
      "outputs": [],
      "source": [
        "# ÈÖçÁΩÆËÆ≠ÁªÉ\n",
        "print(\"‚öôÔ∏è Configuring training...\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    gradient_accumulation_steps=GRADIENT_ACCUMULATION,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    warmup_steps=100,\n",
        "    logging_steps=10,\n",
        "    save_steps=500,\n",
        "    eval_steps=500,\n",
        "    eval_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    load_best_model_at_end=True,\n",
        "    fp16=True,  # Enable fp16 for float16 model\n",
        "    bf16=False,\n",
        "    optim=\"adamw_torch\",  # Standard optimizer for float16 models\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    save_total_limit=3,\n",
        "    report_to=\"none\",\n",
        "    logging_dir=f\"{OUTPUT_DIR}/logs\",\n",
        "    ddp_find_unused_parameters=False,\n",
        "    remove_unused_columns=False,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer=tokenizer,\n",
        "    model=model,\n",
        "    padding=True\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Trainer ready!\")\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üöÄ Starting training...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ÂºÄÂßãËÆ≠ÁªÉ\n",
        "trainer.train()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üéâ Training completed!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1492a771",
      "metadata": {
        "id": "1492a771"
      },
      "outputs": [],
      "source": [
        "# ‰øùÂ≠òÊ®°Âûã\n",
        "print(\"üíæ Saving model...\")\n",
        "trainer.save_model(OUTPUT_DIR)\n",
        "tokenizer.save_pretrained(OUTPUT_DIR)\n",
        "print(f\"‚úÖ Model saved to {OUTPUT_DIR}\")\n",
        "\n",
        "# ‰øùÂ≠òËÆ≠ÁªÉ‰ø°ÊÅØ\n",
        "import json\n",
        "training_info = {\n",
        "    \"model_name\": MODEL_NAME,\n",
        "    \"num_epochs\": NUM_EPOCHS,\n",
        "    \"batch_size\": BATCH_SIZE,\n",
        "    \"learning_rate\": LEARNING_RATE,\n",
        "    \"lora_r\": LORA_R,\n",
        "    \"lora_alpha\": LORA_ALPHA,\n",
        "    \"train_samples\": len(train_dataset),\n",
        "    \"val_samples\": len(eval_dataset),\n",
        "}\n",
        "\n",
        "with open(f\"{OUTPUT_DIR}/training_info.json\", 'w') as f:\n",
        "    json.dump(training_info, f, indent=2)\n",
        "\n",
        "print(\"\\nüìä Training Summary:\")\n",
        "for key, value in training_info.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66fe3514",
      "metadata": {
        "id": "66fe3514"
      },
      "source": [
        "## üß™ Ê≠•È™§6ÔºöÊµãËØïÊ®°Âûã"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba7233b4",
      "metadata": {
        "id": "ba7233b4"
      },
      "outputs": [],
      "source": [
        "# Âø´ÈÄüÊµãËØï (CodeLlama)\n",
        "print(\"üß™ Testing CodeLlama model inference...\")\n",
        "\n",
        "test_instruction = \"Create a new MS cable object at coordinates (186355533, 439556907)\"\n",
        "test_context = \"Application: PowerGrid | Database: ND | Steps: 5\"\n",
        "\n",
        "prompt = f\"\"\"You are a GIS workflow code generator. Generate complete JSON workflow code based on the instruction.\n",
        "\n",
        "Instruction: {test_instruction}\n",
        "Context: {test_context}\n",
        "\n",
        "JSON Code:\n",
        "\"\"\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "print(\"\\nüîÆ Generating...\")\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=512,\n",
        "        temperature=0.7,\n",
        "        do_sample=True,\n",
        "        top_p=0.9,\n",
        "    )\n",
        "\n",
        "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "response = response.split(\"JSON Code:\")[-1].strip()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üìù Test Result:\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Instruction: {test_instruction}\")\n",
        "print(f\"Context: {test_context}\")\n",
        "print(f\"\\nGenerated Output:\\n{response[:500]}...\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91162b41",
      "metadata": {
        "id": "91162b41"
      },
      "source": [
        "## üì¶ Ê≠•È™§7Ôºö‰∏ãËΩΩÊ®°ÂûãÔºàÂèØÈÄâÔºâ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f8ae61a",
      "metadata": {
        "id": "9f8ae61a"
      },
      "outputs": [],
      "source": [
        "# ÊâìÂåÖÊ®°ÂûãÁî®‰∫é‰∏ãËΩΩ\n",
        "!cd /content/drive/MyDrive/gis-models && zip -r codellama-gis-lora.zip codellama-gis-lora/\n",
        "print(\"‚úÖ Model zipped!\")\n",
        "print(f\"üì¶ Location: /content/drive/MyDrive/gis-models/codellama-gis-lora.zip\")\n",
        "print(\"üí° You can download it from Google Drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc7dcf9b",
      "metadata": {
        "id": "bc7dcf9b"
      },
      "source": [
        "## üéØ ‰∏ã‰∏ÄÊ≠•\n",
        "\n",
        "ËÆ≠ÁªÉÂÆåÊàêÂêéÔºå‰Ω†ÂèØ‰ª•Ôºö\n",
        "\n",
        "1. **Âú®Colab‰∏≠ÁªßÁª≠ÊµãËØï**Ôºö‰ΩøÁî®‰∏äÈù¢ÁöÑÊµãËØïÂçïÂÖÉÊ†º\n",
        "2. **‰∏ãËΩΩÊ®°Âûã**Ôºö‰ªéGoogle Drive‰∏ãËΩΩÊâìÂåÖÁöÑÊ®°Âûã\n",
        "3. **Êú¨Âú∞ÈÉ®ÁΩ≤**ÔºöÂ∞ÜÊ®°Âûã‰∏ãËΩΩÂà∞Êú¨Âú∞ËøõË°åÊé®ÁêÜ\n",
        "4. **ËØÑ‰º∞Ê®°Âûã**ÔºöËøêË°åÂÆåÊï¥ÁöÑËØÑ‰º∞ËÑöÊú¨\n",
        "\n",
        "### Êú¨Âú∞‰ΩøÁî®Ê®°Âûã\n",
        "\n",
        "```python\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "\n",
        "# Âä†ËΩΩCodeLlamaÂü∫Â∫ßÊ®°Âûã\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\"codellama/CodeLlama-7b-Instruct-hf\")\n",
        "model = PeftModel.from_pretrained(base_model, \"path/to/codellama-gis-lora\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"path/to/codellama-gis-lora\")\n",
        "\n",
        "# Êé®ÁêÜ\n",
        "# ...\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "**ËÆ≠ÁªÉÂèÇÊï∞Ë∞É‰ºòÂª∫ËÆÆÔºö**\n",
        "- T4 GPU: batch_size=4, gradient_accumulation=4\n",
        "- A100 GPU: batch_size=8-12, gradient_accumulation=2-4\n",
        "- Â¶ÇÊûúÊòæÂ≠ò‰∏çË∂≥ÔºöÂáèÂ∞èbatch_sizeÊàñmax_length\n",
        "- ËÆ≠ÁªÉÊó∂Èó¥‰º∞ËÆ°ÔºöT4Á∫¶4-6Â∞èÊó∂ÔºåA100Á∫¶1-2Â∞èÊó∂\n",
        "\n",
        "**üéâ ÊÅ≠ÂñúÔºÅ‰Ω†Â∑≤ÁªèÂÆåÊàê‰∫ÜGIS‰ª£Á†ÅÁîüÊàêÊ®°ÂûãÁöÑËÆ≠ÁªÉÔºàCodeLlamaÁâàÔºâÔºÅ**"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}