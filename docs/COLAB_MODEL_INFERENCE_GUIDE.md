# Colabç¯å¢ƒä¸‹åŠ è½½å’Œè¯„ä¼°æ¨¡å‹çš„å®Œæ•´è„šæœ¬

# åœ¨ä½ çš„Colab notebookä¸­æŒ‰é¡ºåºè¿è¡Œè¿™äº›å•å…ƒæ ¼

# ============================================================
# å•å…ƒæ ¼1: å¯¼å…¥å’ŒåŸºç¡€è®¾ç½®
# ============================================================

import sys
import os
import json
import torch
import numpy as np
from pathlib import Path
from tqdm import tqdm
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel

print("âœ… åŸºç¡€åº“å¯¼å…¥å®Œæˆ")

# ============================================================
# å•å…ƒæ ¼2: å®šä¹‰æ¨¡å‹åŠ è½½å‡½æ•°
# ============================================================

class GISCodeGenerator:
    """GISä»£ç ç”Ÿæˆå™¨ - CodeLlama + LoRAå¾®è°ƒ"""
    
    def __init__(
        self,
        model_path: str,
        base_model: str = "codellama/CodeLlama-7b-Instruct-hf",
        device: str = "cuda" if torch.cuda.is_available() else "cpu",
        use_fp16: bool = True
    ):
        self.device = device
        self.use_fp16 = use_fp16
        
        print(f"ğŸ”§ åˆå§‹åŒ–æ¨¡å‹...")
        print(f"  è®¾å¤‡: {device}")
        print(f"  FP16: {use_fp16}")
        
        model_path = Path(model_path)
        if not model_path.exists():
            raise FileNotFoundError(f"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
        
        print(f"\nğŸ“– åŠ è½½Tokenizer...")
        self.tokenizer = AutoTokenizer.from_pretrained(
            str(model_path),
            padding_side="right"
        )
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
        print(f"âœ… TokenizeråŠ è½½å®Œæˆ")
        
        print(f"\nğŸ¤– åŠ è½½åŸºç¡€æ¨¡å‹...")
        dtype = torch.float16 if use_fp16 else torch.float32
        
        base_model_obj = AutoModelForCausalLM.from_pretrained(
            base_model,
            torch_dtype=dtype,
            device_map="auto",
            low_cpu_mem_usage=True,
        )
        base_model_obj.config.use_cache = False
        print(f"âœ… åŸºç¡€æ¨¡å‹åŠ è½½å®Œæˆ")
        
        print(f"\nğŸ”§ åŠ è½½LoRAæƒé‡...")
        self.model = PeftModel.from_pretrained(
            base_model_obj,
            str(model_path),
            torch_dtype=dtype,
            device_map="auto",
        )
        self.model.eval()
        print(f"âœ… LoRAæƒé‡åŠ è½½å®Œæˆ")
        print(f"âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼\n")
    
    def generate(
        self,
        instruction: str,
        context: str = "",
        max_new_tokens: int = 512,
        temperature: float = 0.7,
        top_p: float = 0.9,
    ) -> Dict:
        """ç”ŸæˆGISä»£ç """
        
        if context:
            prompt = f"""You are a GIS workflow code generator. Generate complete JSON workflow code based on the instruction.

Instruction: {instruction}
Context: {context}

JSON Code:
"""
        else:
            prompt = f"""You are a GIS workflow code generator. Generate complete JSON workflow code based on the instruction.

Instruction: {instruction}

JSON Code:
"""
        
        inputs = self.tokenizer(prompt, return_tensors="pt").to(self.device)
        
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=max_new_tokens,
                temperature=temperature,
                do_sample=True,
                top_p=top_p,
                pad_token_id=self.tokenizer.pad_token_id,
            )
        
        text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        code = text.split("JSON Code:")[-1].strip()
        
        return {
            "instruction": instruction,
            "context": context,
            "generated_code": code
        }

print("âœ… GISCodeGeneratorç±»å®šä¹‰å®Œæˆ")

# ============================================================
# å•å…ƒæ ¼3: åŠ è½½æ¨¡å‹
# ============================================================

# æŒ‡å®šGoogle Driveä¸­çš„æ¨¡å‹è·¯å¾„
MODEL_PATH = "/content/drive/MyDrive/gis-models/codellama-gis-lora"

print(f"ğŸ“¦ ä»Google DriveåŠ è½½æ¨¡å‹...")
print(f"   è·¯å¾„: {MODEL_PATH}\n")

generator = GISCodeGenerator(MODEL_PATH)

# ============================================================
# å•å…ƒæ ¼4: å¿«é€Ÿæµ‹è¯•æ¨ç†
# ============================================================

print("=" * 70)
print("ğŸ§ª å¿«é€Ÿæµ‹è¯•æ¨ç†")
print("=" * 70)

test_cases = [
    {
        "instruction": "Create a new MS cable object at coordinates (186355533, 439556907)",
        "context": "Application: PowerGrid | Database: ND | Steps: 5"
    },
    {
        "instruction": "Open object in editor and verify field values",
        "context": "Application: NRG Elektra | Database: elektra | Steps: 3"
    },
    {
        "instruction": "Create and update cable object with hierarchy data",
        "context": "Application: GIS | Database: general | Steps: 4"
    }
]

for i, test in enumerate(test_cases, 1):
    print(f"\nğŸ“ æµ‹è¯•æ¡ˆä¾‹ {i}:")
    print(f"  æŒ‡ä»¤: {test['instruction']}")
    print(f"  ä¸Šä¸‹æ–‡: {test['context']}")
    
    result = generator.generate(test['instruction'], test['context'])
    
    print(f"\n  ğŸ’» ç”Ÿæˆä»£ç  (å‰300å­—ç¬¦):")
    code_preview = result['generated_code'][:300]
    print(f"  {code_preview}...")
    
    # æ£€æŸ¥JSONæœ‰æ•ˆæ€§
    try:
        json.loads(result['generated_code'])
        print(f"  âœ… JSONæœ‰æ•ˆ")
    except:
        print(f"  âŒ JSONæ— æ•ˆ")

# ============================================================
# å•å…ƒæ ¼5: å®šä¹‰è¯„ä¼°æŒ‡æ ‡
# ============================================================

def is_valid_json(text: str) -> bool:
    """æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆJSON"""
    try:
        json.loads(text)
        return True
    except:
        return False

def extract_json(text: str):
    """ä»æ–‡æœ¬ä¸­æå–JSON"""
    try:
        return json.loads(text)
    except:
        start = text.find('{')
        end = text.rfind('}')
        if start != -1 and end != -1:
            try:
                return json.loads(text[start:end+1])
            except:
                pass
        return None

def calculate_metrics(instruction, generated_output, reference_output):
    """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
    
    metrics = {}
    
    # 1. JSONæœ‰æ•ˆæ€§
    metrics["json_valid"] = 1.0 if is_valid_json(generated_output) else 0.0
    
    # 2. ç»“æ„åŒ¹é…åº¦
    gen_json = extract_json(generated_output)
    ref_json = extract_json(reference_output)
    
    if gen_json and ref_json:
        # æ£€æŸ¥å¿…è¦å­—æ®µ
        gen_has_workflow = "workflow" in gen_json
        gen_steps = len(gen_json.get("workflow", {}).get("steps", [])) if gen_has_workflow else 0
        ref_steps = len(ref_json.get("workflow", {}).get("steps", [])) if "workflow" in ref_json else 0
        
        structure_score = 0.0
        if gen_has_workflow:
            if gen_steps > 0:
                # æ£€æŸ¥æ¯ä¸ªstepçš„å¿…è¦å­—æ®µ
                required_fields = ["module", "method"]
                valid_steps = sum(
                    1 for step in gen_json["workflow"]["steps"]
                    if all(f in step for f in required_fields)
                )
                structure_score = valid_steps / gen_steps
            
            # æ­¥éª¤æ•°æ¥è¿‘åº¦
            if ref_steps > 0:
                length_ratio = min(gen_steps, ref_steps) / max(gen_steps, ref_steps)
                structure_score = 0.7 * structure_score + 0.3 * length_ratio
        
        metrics["structure_match"] = structure_score
        metrics["step_count"] = gen_steps
    else:
        metrics["structure_match"] = 0.0
        metrics["step_count"] = 0
    
    return metrics

print("âœ… è¯„ä¼°æŒ‡æ ‡å‡½æ•°å®šä¹‰å®Œæˆ")

# ============================================================
# å•å…ƒæ ¼6: åŠ è½½æµ‹è¯•é›†å¹¶è¯„ä¼°
# ============================================================

print("\n" + "=" * 70)
print("ğŸ“‚ åŠ è½½æµ‹è¯•æ•°æ®")
print("=" * 70)

# ä½¿ç”¨éªŒè¯é›†ä½œä¸ºæµ‹è¯•é›†
TEST_DATA_PATH = "data/training/training_data_val.json"

with open(TEST_DATA_PATH, 'r', encoding='utf-8') as f:
    test_data = json.load(f)

print(f"âœ… åŠ è½½äº† {len(test_data)} ä¸ªæµ‹è¯•æ ·æœ¬")

# ============================================================
# å•å…ƒæ ¼7: åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹ (å–å‰50ä¸ªæ ·æœ¬å¿«é€Ÿæµ‹è¯•)
# ============================================================

print("\n" + "=" * 70)
print("ğŸ§ª åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹")
print("=" * 70)

NUM_EVAL_SAMPLES = 50
print(f"è¯„ä¼°æ ·æœ¬æ•°: {NUM_EVAL_SAMPLES}")

all_metrics = []
failed_count = 0

for i, sample in enumerate(tqdm(test_data[:NUM_EVAL_SAMPLES], desc="è¯„ä¼°è¿›åº¦")):
    try:
        instruction = sample.get("instruction", "")
        context = sample.get("input", "")
        reference = sample.get("output", "")
        
        # ç”Ÿæˆ
        result = generator.generate(instruction, context)
        generated = result["generated_code"]
        
        # è®¡ç®—æŒ‡æ ‡
        metrics = calculate_metrics(instruction, generated, reference)
        all_metrics.append(metrics)
        
    except Exception as e:
        failed_count += 1
        all_metrics.append({"json_valid": 0.0, "structure_match": 0.0, "step_count": 0})

print(f"\nâœ… è¯„ä¼°å®Œæˆï¼Œå¤±è´¥æ ·æœ¬: {failed_count}")

# ============================================================
# å•å…ƒæ ¼8: æ‰“å°è¯„ä¼°ç»“æœ
# ============================================================

print("\n" + "=" * 70)
print("ğŸ“Š è¯„ä¼°ç»“æœæ‘˜è¦")
print("=" * 70)

if all_metrics:
    json_valid_scores = [m["json_valid"] for m in all_metrics]
    structure_scores = [m["structure_match"] for m in all_metrics]
    step_counts = [m["step_count"] for m in all_metrics]
    
    print(f"\nâœ… JSONæœ‰æ•ˆæ€§:")
    print(f"   å¹³å‡: {np.mean(json_valid_scores):.2%}")
    print(f"   æœ€å°: {np.min(json_valid_scores):.2%}")
    print(f"   æœ€å¤§: {np.max(json_valid_scores):.2%}")
    
    print(f"\nğŸ—ï¸  ç»“æ„åŒ¹é…åº¦:")
    print(f"   å¹³å‡: {np.mean(structure_scores):.2%}")
    print(f"   æ ‡å‡†å·®: {np.std(structure_scores):.2%}")
    print(f"   æœ€å°: {np.min(structure_scores):.2%}")
    print(f"   æœ€å¤§: {np.max(structure_scores):.2%}")
    
    print(f"\nğŸ“ æ­¥éª¤æ•°ç»Ÿè®¡:")
    print(f"   å¹³å‡: {np.mean(step_counts):.1f}")
    print(f"   ä¸­ä½: {np.median(step_counts):.1f}")
    print(f"   æœ€å¤§: {np.max(step_counts):.0f}")
    
    # ç»¼åˆè¯„åˆ†
    overall_score = (
        0.3 * np.mean(json_valid_scores) +
        0.7 * np.mean(structure_scores)
    )
    
    print(f"\nğŸ¯ ç»¼åˆè¯„åˆ†: {overall_score:.2%}")
    
    if overall_score > 0.8:
        print(f"   ç­‰çº§: â­â­â­â­â­ ä¼˜ç§€")
    elif overall_score > 0.6:
        print(f"   ç­‰çº§: â­â­â­â­ è‰¯å¥½")
    elif overall_score > 0.4:
        print(f"   ç­‰çº§: â­â­â­ ä¸­ç­‰")
    else:
        print(f"   ç­‰çº§: â­â­ éœ€è¦æ”¹è¿›")

print("\n" + "=" * 70)

# ============================================================
# å•å…ƒæ ¼9: ä¿å­˜è¯¦ç»†ç»“æœ (å¯é€‰)
# ============================================================

# å¦‚æœæƒ³ä¿å­˜è¯¦ç»†ç»“æœåˆ°æ–‡ä»¶
OUTPUT_FILE = "/content/drive/MyDrive/gis-models/evaluation_results.json"

# åˆ›å»ºè¯¦ç»†ç»“æœåˆ—è¡¨
detailed_results = []
for i, sample in enumerate(test_data[:NUM_EVAL_SAMPLES]):
    try:
        instruction = sample.get("instruction", "")
        context = sample.get("input", "")
        reference = sample.get("output", "")
        
        result = generator.generate(instruction, context)
        generated = result["generated_code"]
        
        metrics = calculate_metrics(instruction, generated, reference)
        
        detailed_results.append({
            "sample_id": i,
            "instruction": instruction,
            "metrics": metrics
        })
    except:
        pass

# ä¿å­˜
with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
    json.dump(detailed_results, f, indent=2, ensure_ascii=False)

print(f"ğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {OUTPUT_FILE}")
