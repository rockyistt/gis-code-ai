# ä¸ä½¿ç”¨APIç”ŸæˆæŒ‡ä»¤çš„æ›¿ä»£æ–¹æ¡ˆ

## ğŸ¯ æ–¹æ¡ˆå¯¹æ¯”

å¦‚æœæ— æ³•ä½¿ç”¨Qwen/OpenAI APIï¼Œä½ æœ‰ä»¥ä¸‹æ›¿ä»£æ–¹æ¡ˆï¼š

| æ–¹æ¡ˆ | æˆæœ¬ | è´¨é‡ | é€Ÿåº¦ | éš¾åº¦ |
|-----|------|------|------|------|
| âœ… **è§„åˆ™æ¨¡æ¿**ï¼ˆæ¨èï¼‰ | å…è´¹ | ä¸­ | æå¿« | ç®€å• |
| OpenAI API | Â¥10-50 | é«˜ | å¿« | ç®€å• |
| æœ¬åœ°Ollama | å…è´¹ | ä¸­-é«˜ | ä¸­ | ä¸­ç­‰ |
| Hugging Faceæ¨¡å‹ | å…è´¹ | ä¸­-é«˜ | æ…¢ | å¤æ‚ |
| æ‰‹åŠ¨æ ‡æ³¨ | å…è´¹ | æœ€é«˜ | ææ…¢ | ç®€å• |

---

## âœ… æ–¹æ¡ˆ1ï¼šè§„åˆ™æ¨¡æ¿ç”Ÿæˆï¼ˆå¼ºçƒˆæ¨èï¼‰

### ä¼˜åŠ¿
- âœ… **å®Œå…¨å…è´¹**ï¼Œæ— éœ€ä»»ä½•API
- âœ… **é€Ÿåº¦æå¿«**ï¼Œå‡ ç§’å¤„ç†4000+å·¥ä½œæµ
- âœ… **è´¨é‡ç¨³å®š**ï¼Œæ ¹æ®è¯„ä¼°æŠ¥å‘Šï¼Œå¢å¼ºè§„åˆ™æ–¹æ³•è¯„åˆ†0.643
- âœ… **å·²ç»å®ç°**ï¼Œç›´æ¥å¯ç”¨

### ä½¿ç”¨æ–¹æ³•

#### å¿«é€Ÿå¼€å§‹
```powershell
# ä½¿ç”¨å¢å¼ºè§„åˆ™æ–¹æ³•ï¼ˆæ¨èï¼‰
python scripts/generate_instructions_rules.py --method enhanced

# æµ‹è¯•æ¨¡å¼ï¼ˆåªå¤„ç†å‰10ä¸ªï¼‰
python scripts/generate_instructions_rules.py --method enhanced --max-workflows 10
```

#### ä¸‰ç§è§„åˆ™æ–¹æ³•

**1. basicï¼ˆåŸºç¡€ï¼‰- ç®€æ´å¿«é€Ÿ**
```python
# ç¤ºä¾‹è¾“å‡º
æ­¥éª¤çº§: "Create E MS Kabel"
æ–‡ä»¶çº§: "Test workflow to work with E MS Kabel, E HS Kabel in GIS system"
```

**2. enhancedï¼ˆå¢å¼ºï¼‰- æ¨è â­**
```python
# ç¤ºä¾‹è¾“å‡º
æ­¥éª¤çº§: "Create a new E MS Kabel object with 5 attributes in elektra database"
æ–‡ä»¶çº§: "Workflow for NRG Beheerkaart Elektra MS: create E MS Kabel, E HS Kabel in elektra"
```
- è¯„åˆ†: 0.643ï¼ˆç»¼åˆæœ€é«˜ï¼‰
- é€Ÿåº¦: 5,201 workflows/ç§’
- ç‰¹ç‚¹: åŒ…å«æ•°æ®åº“ã€å±æ€§æ•°é‡ç­‰ä¸Šä¸‹æ–‡

**3. contextï¼ˆä¸Šä¸‹æ–‡æ„ŸçŸ¥ï¼‰- æœ€å‹å¥½**
```python
# ç¤ºä¾‹è¾“å‡º
æ­¥éª¤çº§: "Create a new Medium Voltage Cable object"
æ–‡ä»¶çº§: "Electrical network workflow: object creation for Medium Voltage Cable and High Voltage Cable"
```
- è¯„åˆ†: 0.524
- ç‰¹ç‚¹: ä½¿ç”¨å‹å¥½çš„æœ¯è¯­ï¼Œæ›´æ˜“è¯»

### å®Œæ•´å‚æ•°

```powershell
python scripts/generate_instructions_rules.py \
  --input data/processed/parsed_workflows.jsonl \
  --output-dir data/processed \
  --method enhanced \
  --max-workflows 100  # å¯é€‰ï¼šé™åˆ¶å¤„ç†æ•°é‡
```

### è¾“å‡ºæ–‡ä»¶

```
data/processed/
â”œâ”€â”€ file_level_instructions_rule_enhanced.jsonl  # æ–‡ä»¶çº§æŒ‡ä»¤
â””â”€â”€ step_level_instructions_rule_enhanced.jsonl  # æ­¥éª¤çº§æŒ‡ä»¤
```

---

## ğŸ”„ æ–¹æ¡ˆ2ï¼šOpenAI APIï¼ˆå¦‚æœæœ‰é¢„ç®—ï¼‰

å¦‚æœä½ æœ‰OpenAIè´¦å·ï¼ˆæ¯”Qwenæ›´å¸¸è§ï¼‰ï¼š

```powershell
# è®¾ç½®APIå¯†é’¥
$env:OPENAI_API_KEY="sk-..."

# è¿è¡Œ
python src/data_processing/run_pipeline.py --provider openai
```

**æˆæœ¬ä¼°ç®—**ï¼š
- GPT-4o-mini: ~Â¥10-20ï¼ˆ4000ä¸ªå·¥ä½œæµï¼‰
- GPT-4: ~Â¥50-100

---

## ğŸ–¥ï¸ æ–¹æ¡ˆ3ï¼šæœ¬åœ°Ollamaï¼ˆæ— ç½‘ç»œ/éšç§éœ€æ±‚ï¼‰

ä½¿ç”¨æœ¬åœ°LLMï¼Œå®Œå…¨ç¦»çº¿è¿è¡Œã€‚

### å®‰è£…Ollama

```powershell
# ä¸‹è½½å®‰è£…: https://ollama.com/download

# å®‰è£…æ¨¡å‹ï¼ˆæ¨èï¼‰
ollama pull qwen2.5:7b        # 7GBï¼Œè´¨é‡é«˜
ollama pull qwen2.5:3b        # 3GBï¼Œé€Ÿåº¦å¿«
ollama pull mistral:7b        # 7GBï¼Œè‹±æ–‡ä¼˜ç§€
```

### ä¿®æ”¹ä»£ç æ”¯æŒOllama

åˆ›å»º `scripts/generate_instructions_ollama.py`:

```python
import ollama
import json
from pathlib import Path
from tqdm import tqdm

def generate_with_ollama(prompt: str, model: str = "qwen2.5:7b") -> str:
    response = ollama.generate(model=model, prompt=prompt)
    return response['response'].strip()

# å…¶ä½™ä»£ç ç±»ä¼¼ generate_instructions_qwen.py
# å°† API è°ƒç”¨æ›¿æ¢ä¸º generate_with_ollama()
```

**ä¼˜åŠ¿**ï¼š
- âœ… å®Œå…¨å…è´¹å’Œç¦»çº¿
- âœ… æ•°æ®éšç§
- âœ… è´¨é‡æ¥è¿‘äº‘ç«¯API

**åŠ£åŠ¿**ï¼š
- âŒ éœ€è¦GPUï¼ˆCPUä¹Ÿå¯ä»¥ä½†å¾ˆæ…¢ï¼‰
- âŒ éœ€è¦ä¸‹è½½å¤§æ¨¡å‹ï¼ˆ3-7GBï¼‰
- âŒ é€Ÿåº¦è¾ƒæ…¢ï¼ˆçº¦10-30ç§’/workflowï¼‰

---

## ğŸ¤— æ–¹æ¡ˆ4ï¼šHugging Face Transformersï¼ˆæœ€çµæ´»ï¼‰

ä½¿ç”¨å¼€æºæ¨¡å‹ï¼Œå®Œå…¨æ§åˆ¶ã€‚

### å®‰è£…

```powershell
pip install transformers torch accelerate
```

### ä»£ç ç¤ºä¾‹

```python
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

# åŠ è½½æ¨¡å‹ï¼ˆä¸€æ¬¡æ€§ï¼Œå¯ç¼“å­˜ï¼‰
model_name = "Qwen/Qwen2.5-7B-Instruct"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16,
    device_map="auto"
)

def generate_instruction(prompt: str) -> str:
    messages = [
        {"role": "system", "content": "Generate GIS test instructions."},
        {"role": "user", "content": prompt}
    ]
    
    text = tokenizer.apply_chat_template(messages, tokenize=False)
    inputs = tokenizer(text, return_tensors="pt").to(model.device)
    
    outputs = model.generate(**inputs, max_new_tokens=200)
    return tokenizer.decode(outputs[0], skip_special_tokens=True)
```

**ä¼˜åŠ¿**ï¼š
- âœ… å®Œå…¨å…è´¹
- âœ… å¯è‡ªå®šä¹‰å’Œå¾®è°ƒ
- âœ… æ”¯æŒå„ç§å¼€æºæ¨¡å‹

**åŠ£åŠ¿**ï¼š
- âŒ éœ€è¦GPUï¼ˆè‡³å°‘12GBæ˜¾å­˜ï¼‰
- âŒ è®¾ç½®å¤æ‚
- âŒ é¦–æ¬¡ä¸‹è½½æ¨¡å‹éœ€è¦æ—¶é—´

---

## âœ‹ æ–¹æ¡ˆ5ï¼šæ‰‹åŠ¨æ ‡æ³¨ï¼ˆé«˜è´¨é‡ä½†è´¹æ—¶ï¼‰

å¦‚æœåªéœ€è¦å°‘é‡é«˜è´¨é‡æ•°æ®ï¼ˆå¦‚templateæ–‡ä»¶ï¼‰ï¼š

### æµç¨‹

1. è¯»å– `parsed_workflows.jsonl`
2. æ‰‹åŠ¨ä¸ºæ¯ä¸ªworkflowå†™æè¿°
3. ä¿å­˜ä¸ºæ ‡å‡†æ ¼å¼

### å·¥å…·è„šæœ¬

```python
# scripts/manual_annotation.py
import json
from pathlib import Path

workflows = []
with open('data/processed/parsed_workflows.jsonl') as f:
    for line in f:
        workflows.append(json.loads(line))

# åªæ ‡æ³¨é«˜è´¨é‡æ¨¡æ¿
hq_workflows = [w for w in workflows if w.get('is_high_quality')]

print(f"éœ€è¦æ ‡æ³¨ {len(hq_workflows)} ä¸ªé«˜è´¨é‡å·¥ä½œæµ")

for i, workflow in enumerate(hq_workflows):
    print(f"\n--- Workflow {i+1}/{len(hq_workflows)} ---")
    print(f"æ–‡ä»¶: {workflow['file_id']}")
    print(f"åº”ç”¨: {workflow.get('test_app')}")
    print(f"æ­¥éª¤æ•°: {len(workflow.get('steps', []))}")
    
    # æ˜¾ç¤ºæ­¥éª¤æ¦‚è§ˆ
    for j, step in enumerate(workflow['steps'][:3]):
        print(f"  æ­¥éª¤{j+1}: {step.get('method')} {step.get('object')}")
    
    # è¾“å…¥æ ‡æ³¨
    instruction = input("\nè¯·è¾“å…¥æ•´ä½“æè¿°: ")
    workflow['manual_instruction'] = instruction

# ä¿å­˜ç»“æœ...
```

**ä¼˜åŠ¿**ï¼š
- âœ… è´¨é‡æœ€é«˜
- âœ… å®Œå…¨å¯æ§

**åŠ£åŠ¿**ï¼š
- âŒ æè´¹æ—¶ï¼ˆ4000ä¸ªå·¥ä½œæµéœ€è¦å‡ å¤©ï¼‰

---

## ğŸ¯ æ¨èæ–¹æ¡ˆ

### ç«‹å³å¯ç”¨ï¼šè§„åˆ™æ¨¡æ¿ï¼ˆæ–¹æ¡ˆ1ï¼‰

```powershell
# 1åˆ†é’Ÿæå®šæ‰€æœ‰æ•°æ®
python scripts/generate_instructions_rules.py --method enhanced
```

**é€‚ç”¨åœºæ™¯**ï¼š
- âœ… å¿«é€ŸåŸå‹éªŒè¯
- âœ… æ— APIé¢„ç®—
- âœ… éœ€è¦ç¨³å®šè¾“å‡º
- âœ… è´¨é‡è¦æ±‚ä¸­ç­‰ï¼ˆè¯„åˆ†0.643å·²ç»ä¸é”™ï¼‰

### å¦‚æœè¿½æ±‚æ›´é«˜è´¨é‡

1. **å…ˆç”¨è§„åˆ™ç”ŸæˆåŸºç¡€æ•°æ®**ï¼ˆæ–¹æ¡ˆ1ï¼‰
2. **æ‰‹åŠ¨æ ‡æ³¨å°‘é‡é«˜è´¨é‡æ ·æœ¬**ï¼ˆæ–¹æ¡ˆ5ï¼Œåªæ ‡æ³¨12ä¸ªtemplateï¼‰
3. **ç”¨é«˜è´¨é‡æ ·æœ¬åšfew-shot**ï¼ˆæä¾›ç»™è§„åˆ™æˆ–æœ¬åœ°æ¨¡å‹å‚è€ƒï¼‰

### å¦‚æœæœ‰GPU

è€ƒè™‘ä½¿ç”¨ **Ollama**ï¼ˆæ–¹æ¡ˆ3ï¼‰ï¼š
- ä¸€æ¬¡å®‰è£…ï¼Œæ°¸ä¹…å…è´¹
- è´¨é‡æ¥è¿‘API
- é€‚åˆé•¿æœŸé¡¹ç›®

---

## ğŸ“Š è´¨é‡å¯¹æ¯”ï¼ˆæ ¹æ®è¯„ä¼°æŠ¥å‘Šï¼‰

| æ–¹æ³• | ç»¼åˆè¯„åˆ† | æè¿°è´¨é‡ | ä¸šåŠ¡é€»è¾‘ | é€Ÿåº¦ |
|------|---------|---------|---------|------|
| **å¢å¼ºè§„åˆ™** | 0.643 | 0.513 | 0.479 | 5,201/s |
| åŸºç¡€è§„åˆ™ | 0.556 | 0.371 | 0.136 | 2,794/s |
| ä¸Šä¸‹æ–‡æ„ŸçŸ¥ | 0.524 | 0.324 | 0.146 | 4,887/s |
| Qwen API | ~0.7-0.8 | ~0.6-0.7 | ~0.6-0.7 | ~1-2/s |

**ç»“è®º**ï¼šå¢å¼ºè§„åˆ™æ–¹æ³•çš„è´¨é‡å·²ç»è¾¾åˆ°å¯ç”¨æ°´å¹³ï¼Œç‰¹åˆ«é€‚åˆå¿«é€Ÿè¿­ä»£ï¼

---

## ğŸš€ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### æ¨èæµç¨‹

```powershell
# ç¬¬1æ­¥ï¼šä½¿ç”¨è§„åˆ™ç”Ÿæˆæ‰€æœ‰æ•°æ®ï¼ˆ1åˆ†é’Ÿï¼‰
python scripts/generate_instructions_rules.py --method enhanced

# ç¬¬2æ­¥ï¼šæŸ¥çœ‹ç”Ÿæˆæ•ˆæœ
head -n 5 data/processed/file_level_instructions_rule_enhanced.jsonl

# ç¬¬3æ­¥ï¼šå¦‚æœæ»¡æ„ï¼Œç›´æ¥ç”¨äºè®­ç»ƒ
# å¦‚æœä¸æ»¡æ„ï¼Œå†è€ƒè™‘å…¶ä»–æ–¹æ¡ˆ
```

### æ··åˆç­–ç•¥ï¼ˆæœ€ä½³å®è·µï¼‰

```python
# 1. è§„åˆ™ç”Ÿæˆæ‰€æœ‰æ•°æ®ï¼ˆå¿«é€Ÿï¼‰
# 2. æ‰‹åŠ¨æ ‡æ³¨12ä¸ªé«˜è´¨é‡æ¨¡æ¿ï¼ˆ1å°æ—¶ï¼‰
# 3. ç”¨æ‰‹åŠ¨æ ‡æ³¨çš„åšéªŒè¯é›†
# 4. ç”¨è§„åˆ™ç”Ÿæˆçš„åšè®­ç»ƒé›†
```

è¿™æ ·æ—¢ä¿è¯äº†é€Ÿåº¦ï¼Œåˆä¿è¯äº†è´¨é‡ï¼
