"""
å¢å¼ºç‰ˆæŒ‡ä»¤ç”Ÿæˆå™¨ - æ”¯æŒå…³é”®è¯æƒé‡å’Œç»“æ„åŒ–è¡¨è¾¾

æ–°ç‰¹æ€§ï¼š
1. å…³é”®è¯æƒé‡æ ‡æ³¨ï¼ˆä¸ºè®­ç»ƒæ—¶çš„attentionæœºåˆ¶æä¾›æ”¯æŒï¼‰
2. åŠ¨ä½œè¯å¼ºè°ƒå’ŒåŒä¹‰è¯å˜åŒ–
3. ç»“æ„åŒ–æ¨¡æ¿ï¼ˆåŠ¨ä½œ+å®¾è¯­+çŠ¶è¯­ï¼‰çš„å¤šæ ·åŒ–è¡¨è¾¾
4. æ”¯æŒè¾“å‡ºå¸¦æƒé‡æ ‡è®°çš„æ ¼å¼
"""

import json
import argparse
from pathlib import Path
from typing import Dict, List, Any, Tuple
import logging
from tqdm import tqdm
import random

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class KeywordWeights:
    """å…³é”®è¯æƒé‡å®šä¹‰"""
    
    # æƒé‡ç­‰çº§
    CRITICAL = 3.0    # æ ¸å¿ƒåŠ¨ä½œè¯
    HIGH = 2.0        # é‡è¦å¯¹è±¡å’Œæ–¹æ³•
    MEDIUM = 1.5      # ä¿®é¥°è¯­å’Œä¸Šä¸‹æ–‡
    NORMAL = 1.0      # ä¸€èˆ¬è¯æ±‡
    
    # åŠ¨ä½œè¯æƒé‡æ˜ å°„
    ACTION_WEIGHTS = {
        "Create": CRITICAL,
        "Update": CRITICAL,
        "Delete": CRITICAL,
        "Open": HIGH,
        "Navigate": HIGH,
        "Click": HIGH,
        "Verify": HIGH,
        "Select": HIGH,
        "Switch": MEDIUM,
        "Perform": MEDIUM,
    }
    
    # å¯¹è±¡ç±»å‹æƒé‡
    OBJECT_WEIGHTS = {
        "object": HIGH,
        "dataset": MEDIUM,
        "database": MEDIUM,
        "tab": MEDIUM,
        "button": MEDIUM,
        "field": MEDIUM,
    }


class StructuredInstructionTemplate:
    """ç»“æ„åŒ–æŒ‡ä»¤æ¨¡æ¿ï¼ˆåŠ¨ä½œ+å®¾è¯­+çŠ¶è¯­ï¼‰"""
    
    def __init__(self):
        # åŠ¨ä½œè¯åŠå…¶åŒä¹‰è¯å˜ä½“
        self.action_synonyms = {
            "Create": ["Create", "Add", "Insert", "Generate"],
            "Update": ["Update", "Modify", "Change", "Edit"],
            "Delete": ["Delete", "Remove", "Erase"],
            "Open": ["Open", "Access", "Load"],
            "Navigate": ["Navigate to", "Go to", "Switch to", "Move to"],
            "Click": ["Click", "Press", "Activate"],
            "Select": ["Select", "Choose", "Pick"],
            "Verify": ["Verify", "Check", "Validate", "Confirm"],
        }
        
        # å®¾è¯­å¢å¼ºæè¿°
        self.object_enhancers = {
            "object": ["object", "entity", "record", "item"],
            "dataset": ["dataset", "data collection", "data source"],
            "database": ["database", "data store", "repository"],
        }
        
        # çŠ¶è¯­æ¨¡æ¿å˜ä½“
        self.adverbial_templates = {
            "in_database": [
                "in {database} database",
                "within {database}",
                "from {database} dataset",
                "in the {database} repository"
            ],
            "with_attributes": [
                "with {count} attributes",
                "having {count} specified attributes",
                "containing {count} properties",
                "with {count} defined fields"
            ],
            "location": [
                "in {location}",
                "at {location}",
                "within {location}"
            ]
        }
    
    def get_action_variant(self, action: str, use_synonym: bool = False) -> str:
        """è·å–åŠ¨ä½œè¯ï¼ˆå¯é€‰ä½¿ç”¨åŒä¹‰è¯ï¼‰"""
        if use_synonym and action in self.action_synonyms:
            return random.choice(self.action_synonyms[action])
        return action
    
    def get_object_variant(self, obj_type: str) -> str:
        """è·å–å®¾è¯­å˜ä½“"""
        if obj_type in self.object_enhancers:
            return random.choice(self.object_enhancers[obj_type])
        return obj_type
    
    def get_adverbial_variant(self, adv_type: str, **kwargs) -> str:
        """è·å–çŠ¶è¯­å˜ä½“"""
        if adv_type in self.adverbial_templates:
            template = random.choice(self.adverbial_templates[adv_type])
            return template.format(**kwargs)
        return ""


class WeightedInstructionGenerator:
    """å¸¦æƒé‡çš„æŒ‡ä»¤ç”Ÿæˆå™¨"""
    
    def __init__(self, use_variants: bool = True, mark_weights: bool = False):
        """
        Args:
            use_variants: æ˜¯å¦ä½¿ç”¨åŒä¹‰è¯å˜ä½“
            mark_weights: æ˜¯å¦åœ¨è¾“å‡ºä¸­æ ‡è®°æƒé‡
        """
        self.templates = StructuredInstructionTemplate()
        self.use_variants = use_variants
        self.mark_weights = mark_weights
        
        # æ ¸å¿ƒåŠ¨ä½œæ˜ å°„ï¼ˆç»“æ„åŒ–ï¼‰
        self.action_patterns = {
            "Create": self._create_pattern,
            "Update": self._update_pattern,
            "Delete": self._delete_pattern,
            "Open Object": self._open_pattern,
            "Open Object with ID": self._open_id_pattern,
            "Select Tab": self._select_tab_pattern,
            "Click Oneshot Button": self._click_button_pattern,
            "Verify Field": self._verify_pattern,
            "Switch Spatial Context": self._switch_context_pattern,
            "Select first HV object": self._select_hv_pattern,
            "Select second HV object": self._select_hv_pattern,
            "Datamodel Check": self._datamodel_check_pattern,
        }
    
    def _mark_keyword(self, word: str, weight: float) -> str:
        """æ ‡è®°å…³é”®è¯æƒé‡"""
        if self.mark_weights and weight > KeywordWeights.NORMAL:
            # ä½¿ç”¨ç‰¹æ®Šæ ‡è®°åŒ…è£¹é«˜æƒé‡è¯
            if weight >= KeywordWeights.CRITICAL:
                return f"**{word}**"  # åŒæ˜Ÿå·è¡¨ç¤ºå…³é”®
            elif weight >= KeywordWeights.HIGH:
                return f"*{word}*"    # å•æ˜Ÿå·è¡¨ç¤ºé‡è¦
        return word
    
    def _clean_object_name(self, obj: str) -> str:
        """æ¸…ç†å¯¹è±¡å"""
        return obj.replace(':', '').strip()
    
    def _create_pattern(self, step: Dict) -> Tuple[str, List[Tuple[str, float]]]:
        """åˆ›å»ºæ“ä½œæ¨¡å¼ï¼š[åŠ¨ä½œ] + [å®¾è¯­] + [çŠ¶è¯­(å±æ€§/ä½ç½®)]"""
        obj = self._clean_object_name(step.get('object', ''))
        database = step.get('database', '').replace(':', '')
        
        # æå–å±æ€§æ•°é‡
        attr_count = self._extract_attributes_count(step)
        
        # æ„å»ºæŒ‡ä»¤ï¼ˆç»“æ„åŒ–ï¼‰
        action = self.templates.get_action_variant("Create", self.use_variants)
        action_marked = self._mark_keyword(action, KeywordWeights.CRITICAL)
        
        obj_marked = self._mark_keyword(obj, KeywordWeights.HIGH)
        
        # çŠ¶è¯­éƒ¨åˆ†
        adverbials = []
        if attr_count > 0:
            adv = self.templates.get_adverbial_variant("with_attributes", count=attr_count)
            adverbials.append(adv)
        
        if database:
            adv = self.templates.get_adverbial_variant("in_database", database=database)
            adverbials.append(self._mark_keyword(database, KeywordWeights.MEDIUM) + " database")
        
        # ç»„åˆï¼šåŠ¨ä½œ + å®¾è¯­ + çŠ¶è¯­
        parts = [action_marked, obj_marked, "object"]
        if adverbials:
            parts.extend(adverbials)
        
        instruction = " ".join(parts)
        
        # è¿”å›æŒ‡ä»¤å’Œæƒé‡åˆ—è¡¨
        weights = [
            (action, KeywordWeights.CRITICAL),
            (obj, KeywordWeights.HIGH),
            ("object", KeywordWeights.HIGH),
        ]
        if database:
            weights.append((database, KeywordWeights.MEDIUM))
        
        return instruction, weights
    
    def _update_pattern(self, step: Dict) -> Tuple[str, List[Tuple[str, float]]]:
        """æ›´æ–°æ“ä½œæ¨¡å¼"""
        obj = self._clean_object_name(step.get('object', ''))
        action = self.templates.get_action_variant("Update", self.use_variants)
        
        action_marked = self._mark_keyword(action, KeywordWeights.CRITICAL)
        obj_marked = self._mark_keyword(obj, KeywordWeights.HIGH)
        
        instruction = f"{action_marked} {obj_marked} object with modified field values"
        weights = [
            (action, KeywordWeights.CRITICAL),
            (obj, KeywordWeights.HIGH),
            ("modified", KeywordWeights.MEDIUM),
        ]
        return instruction, weights
    
    def _delete_pattern(self, step: Dict) -> Tuple[str, List[Tuple[str, float]]]:
        """åˆ é™¤æ“ä½œæ¨¡å¼"""
        obj = self._clean_object_name(step.get('object', ''))
        action = self.templates.get_action_variant("Delete", self.use_variants)
        
        action_marked = self._mark_keyword(action, KeywordWeights.CRITICAL)
        obj_marked = self._mark_keyword(obj, KeywordWeights.HIGH)
        
        instruction = f"{action_marked} {obj_marked} object"
        weights = [
            (action, KeywordWeights.CRITICAL),
            (obj, KeywordWeights.HIGH),
        ]
        return instruction, weights
    
    def _open_pattern(self, step: Dict) -> Tuple[str, List[Tuple[str, float]]]:
        """æ‰“å¼€å¯¹è±¡æ¨¡å¼"""
        obj = self._clean_object_name(step.get('object', ''))
        database = step.get('database', '').replace(':', '')
        action = self.templates.get_action_variant("Open", self.use_variants)
        
        action_marked = self._mark_keyword(action, KeywordWeights.HIGH)
        obj_marked = self._mark_keyword(obj, KeywordWeights.HIGH)
        
        if database:
            db_marked = self._mark_keyword(database, KeywordWeights.MEDIUM)
            instruction = f"{action_marked} {obj_marked} object in {db_marked} dataset"
            weights = [(action, KeywordWeights.HIGH), (obj, KeywordWeights.HIGH), (database, KeywordWeights.MEDIUM)]
        else:
            instruction = f"{action_marked} {obj_marked} object"
            weights = [(action, KeywordWeights.HIGH), (obj, KeywordWeights.HIGH)]
        
        return instruction, weights
    
    def _open_id_pattern(self, step: Dict) -> Tuple[str, List[Tuple[str, float]]]:
        """é€šè¿‡IDæ‰“å¼€å¯¹è±¡æ¨¡å¼"""
        obj = self._clean_object_name(step.get('object', ''))
        action = self.templates.get_action_variant("Open", self.use_variants)
        
        action_marked = self._mark_keyword(action, KeywordWeights.HIGH)
        obj_marked = self._mark_keyword(obj, KeywordWeights.HIGH)
        id_marked = self._mark_keyword("ID", KeywordWeights.MEDIUM)
        
        instruction = f"{action_marked} {obj_marked} object by {id_marked}"
        weights = [
            (action, KeywordWeights.HIGH),
            (obj, KeywordWeights.HIGH),
            ("ID", KeywordWeights.MEDIUM),
        ]
        return instruction, weights
    
    def _select_tab_pattern(self, step: Dict) -> Tuple[str, List[Tuple[str, float]]]:
        """é€‰æ‹©æ ‡ç­¾é¡µæ¨¡å¼"""
        obj = self._clean_object_name(step.get('object', ''))
        action = self.templates.get_action_variant("Navigate", self.use_variants)
        
        action_marked = self._mark_keyword(action, KeywordWeights.HIGH)
        obj_marked = self._mark_keyword(obj, KeywordWeights.MEDIUM)
        
        instruction = f"{action_marked} {obj_marked} tab"
        weights = [
            (action, KeywordWeights.HIGH),
            (obj, KeywordWeights.MEDIUM),
        ]
        return instruction, weights
    
    def _click_button_pattern(self, step: Dict) -> Tuple[str, List[Tuple[str, float]]]:
        """ç‚¹å‡»æŒ‰é’®æ¨¡å¼"""
        obj = self._clean_object_name(step.get('object', ''))
        action = self.templates.get_action_variant("Click", self.use_variants)
        
        action_marked = self._mark_keyword(action, KeywordWeights.HIGH)
        obj_marked = self._mark_keyword(obj, KeywordWeights.MEDIUM)
        
        instruction = f"{action_marked} {obj_marked} button"
        weights = [
            (action, KeywordWeights.HIGH),
            (obj, KeywordWeights.MEDIUM),
        ]
        return instruction, weights
    
    def _verify_pattern(self, step: Dict) -> Tuple[str, List[Tuple[str, float]]]:
        """éªŒè¯å­—æ®µæ¨¡å¼"""
        obj = self._clean_object_name(step.get('object', ''))
        action = self.templates.get_action_variant("Verify", self.use_variants)
        
        action_marked = self._mark_keyword(action, KeywordWeights.HIGH)
        obj_marked = self._mark_keyword(obj, KeywordWeights.MEDIUM)
        
        instruction = f"{action_marked} {obj_marked} field values"
        weights = [
            (action, KeywordWeights.HIGH),
            (obj, KeywordWeights.MEDIUM),
        ]
        return instruction, weights
    
    def _switch_context_pattern(self, step: Dict) -> Tuple[str, List[Tuple[str, float]]]:
        """åˆ‡æ¢ç©ºé—´ä¸Šä¸‹æ–‡æ¨¡å¼"""
        obj = self._clean_object_name(step.get('object', ''))
        action = "Switch spatial context"
        
        action_marked = self._mark_keyword("Switch", KeywordWeights.MEDIUM)
        obj_marked = self._mark_keyword(obj, KeywordWeights.MEDIUM)
        
        instruction = f"{action_marked} spatial context to {obj_marked}"
        weights = [
            ("Switch", KeywordWeights.MEDIUM),
            (obj, KeywordWeights.MEDIUM),
        ]
        return instruction, weights
    
    def _select_hv_pattern(self, step: Dict) -> Tuple[str, List[Tuple[str, float]]]:
        """é€‰æ‹©å±‚çº§è§†å›¾å¯¹è±¡æ¨¡å¼"""
        obj = self._clean_object_name(step.get('object', ''))
        method = step.get('method', '')
        position = "first" if "first" in method else "second"
        
        action = self.templates.get_action_variant("Select", self.use_variants)
        action_marked = self._mark_keyword(action, KeywordWeights.HIGH)
        obj_marked = self._mark_keyword(obj, KeywordWeights.MEDIUM)
        
        instruction = f"{action_marked} {position} {obj_marked} in hierarchy viewer"
        weights = [
            (action, KeywordWeights.HIGH),
            (obj, KeywordWeights.MEDIUM),
        ]
        return instruction, weights
    
    def _datamodel_check_pattern(self, step: Dict) -> Tuple[str, List[Tuple[str, float]]]:
        """æ•°æ®æ¨¡å‹æ£€æŸ¥æ¨¡å¼"""
        obj = self._clean_object_name(step.get('object', ''))
        
        action_marked = self._mark_keyword("Check", KeywordWeights.HIGH)
        obj_marked = self._mark_keyword(obj, KeywordWeights.MEDIUM)
        
        instruction = f"{action_marked} data consistency for {obj_marked}"
        weights = [
            ("Check", KeywordWeights.HIGH),
            (obj, KeywordWeights.MEDIUM),
        ]
        return instruction, weights
    
    def _extract_attributes_count(self, step: Dict) -> int:
        """æå–å±æ€§æ•°é‡"""
        test_data = step.get('test_data', {})
        for section in ['create', 'update']:
            if section in test_data and test_data[section]:
                data = test_data[section]
                for key, value in data.items():
                    if key.startswith('FLD_CSTM') and isinstance(value, dict):
                        return len([k for k in value.keys() if k != 'ID'])
        return 0
    
    def generate_step_instruction(self, step: Dict) -> Dict[str, Any]:
        """ç”Ÿæˆæ­¥éª¤çº§æŒ‡ä»¤ï¼ˆå¸¦æƒé‡ä¿¡æ¯ï¼‰"""
        method = step.get('method', '')
        
        # ä½¿ç”¨å¯¹åº”çš„æ¨¡å¼ç”Ÿæˆ
        if method in self.action_patterns:
            instruction, weights = self.action_patterns[method](step)
        else:
            # é»˜è®¤æ¨¡å¼
            obj = self._clean_object_name(step.get('object', ''))
            instruction = f"{method} {obj}"
            weights = [(method, KeywordWeights.NORMAL), (obj, KeywordWeights.MEDIUM)]
        
        return {
            "instruction": instruction,
            "weights": weights,
            "structure": self._analyze_structure(instruction)
        }
    
    def _analyze_structure(self, instruction: str) -> Dict[str, str]:
        """åˆ†ææŒ‡ä»¤ç»“æ„ï¼ˆåŠ¨ä½œ+å®¾è¯­+çŠ¶è¯­ï¼‰"""
        words = instruction.replace('*', '').split()
        
        # ç®€å•çš„ç»“æ„åˆ†æ
        structure = {
            "action": words[0] if words else "",
            "object": "",
            "adverbials": []
        }
        
        # å¯»æ‰¾å®¾è¯­ï¼ˆé€šå¸¸åœ¨åŠ¨ä½œè¯åï¼‰
        for i, word in enumerate(words[1:], 1):
            if word.lower() in ['object', 'tab', 'button', 'field']:
                if i > 0:
                    structure["object"] = " ".join(words[1:i+1])
                break
        
        # å‰©ä½™éƒ¨åˆ†ä½œä¸ºçŠ¶è¯­
        if structure["object"]:
            obj_end = len(structure["object"].split()) + 1
            if len(words) > obj_end:
                structure["adverbials"] = words[obj_end:]
        
        return structure
    
    def generate_file_instruction(self, workflow: Dict) -> Dict[str, Any]:
        """ç”Ÿæˆæ–‡ä»¶çº§æŒ‡ä»¤ï¼ˆå¸¦æƒé‡å’Œç»“æ„ï¼‰"""
        steps = workflow.get('steps', [])
        app = workflow.get('test_app', 'GIS system')
        
        # æ”¶é›†å…³é”®ä¿¡æ¯
        actions = set()
        objects = set()
        databases = set()
        
        for step in steps:
            method = step.get('method', '')
            obj = self._clean_object_name(step.get('object', ''))
            db = step.get('database', '').replace(':', '')
            
            if method in ['Create', 'Update', 'Delete']:
                actions.add(method.lower())
            
            if obj and obj not in ['Default', 'Object Control', 'Routes', 'Object Editor']:
                objects.add(obj)
            
            if db:
                databases.add(db)
        
        # æ„å»ºæ–‡ä»¶çº§æŒ‡ä»¤
        action_str = self._mark_keyword(", ".join(sorted(actions)), KeywordWeights.CRITICAL) if actions else "manage"
        
        if len(objects) <= 3:
            obj_list = [self._mark_keyword(obj, KeywordWeights.HIGH) for obj in list(objects)[:3]]
            obj_str = ", ".join(obj_list)
        else:
            obj_str = f"multiple objects"
        
        db_str = ""
        if databases:
            db = list(databases)[0]
            db_str = f" in {self._mark_keyword(db, KeywordWeights.MEDIUM)}"
        
        instruction = f"Workflow: {action_str} {obj_str}{db_str} in {app}"
        
        # æƒé‡ä¿¡æ¯
        weights = []
        for action in actions:
            weights.append((action, KeywordWeights.CRITICAL))
        for obj in list(objects)[:3]:
            weights.append((obj, KeywordWeights.HIGH))
        if databases:
            weights.append((list(databases)[0], KeywordWeights.MEDIUM))
        
        return {
            "instruction": instruction,
            "weights": weights,
            "actions": list(actions),
            "objects": list(objects)[:5],
            "databases": list(databases)
        }


def main():
    parser = argparse.ArgumentParser(description="å¢å¼ºç‰ˆæŒ‡ä»¤ç”Ÿæˆå™¨ï¼ˆæ”¯æŒæƒé‡å’Œç»“æ„åŒ–ï¼‰")
    parser.add_argument('--input', type=str,
                       default='data/processed/parsed_workflows.jsonl',
                       help='è¾“å…¥æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output-dir', type=str,
                       default='data/processed',
                       help='è¾“å‡ºç›®å½•')
    parser.add_argument('--use-variants', action='store_true',
                       help='ä½¿ç”¨åŒä¹‰è¯å˜ä½“å¢åŠ å¤šæ ·æ€§')
    parser.add_argument('--mark-weights', action='store_true',
                       help='åœ¨è¾“å‡ºä¸­æ ‡è®°å…³é”®è¯æƒé‡ï¼ˆ**å…³é”®** *é‡è¦*ï¼‰')
    parser.add_argument('--max-workflows', type=int,
                       help='æœ€å¤§å¤„ç†å·¥ä½œæµæ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰')
    
    args = parser.parse_args()
    
    # è¯»å–å·¥ä½œæµæ•°æ®
    input_path = Path(args.input)
    if not input_path.exists():
        logger.error(f"âŒ Input file not found: {input_path}")
        return
    
    logger.info(f"ğŸ“– Reading workflows from {input_path}")
    workflows = []
    with open(input_path, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                workflows.append(json.loads(line))
    
    logger.info(f"âœ… Loaded {len(workflows)} workflows")
    
    # é™åˆ¶æ•°é‡ï¼ˆå¦‚æœæŒ‡å®šï¼‰
    if args.max_workflows:
        workflows = workflows[:args.max_workflows]
        logger.info(f"ğŸ“Š Limited to {len(workflows)} workflows for testing")
    
    # åˆ›å»ºç”Ÿæˆå™¨
    generator = WeightedInstructionGenerator(
        use_variants=args.use_variants,
        mark_weights=args.mark_weights
    )
    
    # è¾“å‡ºè·¯å¾„
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    suffix = "_weighted"
    if args.use_variants:
        suffix += "_variants"
    if args.mark_weights:
        suffix += "_marked"
    
    file_output = output_dir / f"file_level_instructions{suffix}.jsonl"
    step_output = output_dir / f"step_level_instructions{suffix}.jsonl"
    
    # ç”Ÿæˆæ–‡ä»¶çº§æŒ‡ä»¤
    logger.info("ğŸ“ Generating file-level instructions...")
    file_results = []
    for workflow in tqdm(workflows, desc="File-level"):
        result = generator.generate_file_instruction(workflow)
        
        output = {
            "file_id": workflow.get("file_id", ""),
            "is_high_quality": workflow.get("is_high_quality", False),
            "instruction": result["instruction"],
            "provider": "rule_weighted",
            "test_app": workflow.get("test_app", ""),
            "total_steps": len(workflow.get("steps", [])),
            "keywords": result["weights"],  # å…³é”®è¯æƒé‡
            "actions": result["actions"],
            "objects": result["objects"],
            "databases": result["databases"]
        }
        file_results.append(output)
    
    with open(file_output, 'w', encoding='utf-8') as f:
        for result in file_results:
            f.write(json.dumps(result, ensure_ascii=False) + '\n')
    
    logger.info(f"âœ… File-level instructions saved to {file_output}")
    
    # ç”Ÿæˆæ­¥éª¤çº§æŒ‡ä»¤
    logger.info("ğŸ“ Generating step-level instructions...")
    step_results = []
    for workflow in tqdm(workflows, desc="Step-level"):
        file_id = workflow.get("file_id", "")
        is_hq = workflow.get("is_high_quality", False)
        steps = workflow.get("steps", [])
        
        for i, step in enumerate(steps):
            result = generator.generate_step_instruction(step)
            
            output = {
                "file_id": file_id,
                "step_index": i,
                "step_type": step.get("module", ""),
                "is_high_quality": is_hq,
                "instruction": result["instruction"],
                "provider": "rule_weighted",
                "module": step.get("module", ""),
                "method": step.get("method", ""),
                "keywords": result["weights"],  # å…³é”®è¯æƒé‡
                "structure": result["structure"]  # ç»“æ„åˆ†æ
            }
            step_results.append(output)
    
    with open(step_output, 'w', encoding='utf-8') as f:
        for result in step_results:
            f.write(json.dumps(result, ensure_ascii=False) + '\n')
    
    logger.info(f"âœ… Step-level instructions saved to {step_output}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    logger.info("\n" + "="*60)
    logger.info("ğŸ‰ å¢å¼ºç‰ˆæŒ‡ä»¤ç”Ÿæˆå®Œæˆï¼")
    logger.info(f"ğŸ“„ æ–‡ä»¶çº§: {file_output}")
    logger.info(f"ğŸ“ æ­¥éª¤çº§: {step_output}")
    logger.info(f"âš™ï¸  é€‰é¡¹:")
    logger.info(f"   - ä½¿ç”¨åŒä¹‰è¯å˜ä½“: {args.use_variants}")
    logger.info(f"   - æ ‡è®°æƒé‡: {args.mark_weights}")
    logger.info(f"ğŸ“Š ç»Ÿè®¡:")
    logger.info(f"   - å·¥ä½œæµæ•°: {len(file_results)}")
    logger.info(f"   - æ­¥éª¤æ•°: {len(step_results)}")
    logger.info("="*60)


if __name__ == "__main__":
    main()
