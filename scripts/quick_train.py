#!/usr/bin/env python
"""
å¿«é€Ÿè®­ç»ƒè„šæœ¬ - ä¸€é”®å®Œæˆæ•°æ®å‡†å¤‡å’Œæ¨¡å‹è®­ç»ƒ

ä½¿ç”¨æ–¹å¼ï¼š
  python scripts/quick_train.py           # ä½¿ç”¨é»˜è®¤é…ç½®
  python scripts/quick_train.py --test    # å¿«é€Ÿæµ‹è¯•æ¨¡å¼
  python scripts/quick_train.py --full    # å®Œæ•´è®­ç»ƒ
"""

import os
import sys
import argparse
import subprocess
import logging
from pathlib import Path

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class QuickTrainer:
    """å¿«é€Ÿè®­ç»ƒå·¥å…·"""
    
    def __init__(self, test_mode: bool = False):
        self.test_mode = test_mode
        self.project_root = Path(__file__).parent.parent
        
    def run_command(self, cmd: list, description: str):
        """è¿è¡Œå‘½ä»¤"""
        logger.info(f"ğŸš€ {description}")
        logger.info(f"   å‘½ä»¤: {' '.join(cmd)}")
        
        result = subprocess.run(cmd, cwd=self.project_root)
        
        if result.returncode != 0:
            logger.error(f"âŒ å¤±è´¥: {description}")
            sys.exit(1)
        
        logger.info(f"âœ… å®Œæˆ: {description}")
        return result
    
    def check_dependencies(self):
        """æ£€æŸ¥ä¾èµ–æ˜¯å¦å®‰è£…"""
        logger.info("ğŸ” æ£€æŸ¥ä¾èµ–...")
        
        required_packages = ['transformers', 'peft', 'torch', 'datasets', 'accelerate']
        missing = []
        
        for package in required_packages:
            try:
                __import__(package)
            except ImportError:
                missing.append(package)
        
        if missing:
            logger.warning(f"âš ï¸  ç¼ºå°‘ä¾èµ–: {', '.join(missing)}")
            logger.info("ğŸ’¡ å®‰è£…ä¾èµ–: pip install -r requirements.txt")
            
            response = input("æ˜¯å¦ç°åœ¨å®‰è£…ï¼Ÿ(y/n): ")
            if response.lower() == 'y':
                self.run_command(
                    [sys.executable, '-m', 'pip', 'install', '-r', 'requirements.txt'],
                    "å®‰è£…ä¾èµ–"
                )
            else:
                logger.error("âŒ è¯·å…ˆå®‰è£…ä¾èµ–")
                sys.exit(1)
        else:
            logger.info("âœ… æ‰€æœ‰ä¾èµ–å·²å®‰è£…")
    
    def check_data_files(self):
        """æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        logger.info("ğŸ“‚ æ£€æŸ¥æ•°æ®æ–‡ä»¶...")
        
        instructions_file = self.project_root / "data/processed/step_level_instructions_weighted_variants_marked.jsonl"
        workflows_file = self.project_root / "data/processed/parsed_workflows.jsonl"
        
        if not instructions_file.exists():
            logger.error(f"âŒ æŒ‡ä»¤æ–‡ä»¶ä¸å­˜åœ¨: {instructions_file}")
            logger.info("ğŸ’¡ è¯·å…ˆè¿è¡Œ: python scripts/generate_instructions_weighted.py")
            sys.exit(1)
        
        if not workflows_file.exists():
            logger.error(f"âŒ å·¥ä½œæµæ–‡ä»¶ä¸å­˜åœ¨: {workflows_file}")
            logger.info("ğŸ’¡ è¯·å…ˆè¿è¡Œå·¥ä½œæµè§£æ")
            sys.exit(1)
        
        logger.info("âœ… æ•°æ®æ–‡ä»¶å®Œæ•´")
    
    def prepare_training_data(self):
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        cmd = [sys.executable, 'src/training/prepare_training_data.py']
        
        if self.test_mode:
            cmd.extend(['--max-samples', '1000'])
        
        self.run_command(cmd, "å‡†å¤‡è®­ç»ƒæ•°æ®")
    
    def train_model(self):
        """è®­ç»ƒæ¨¡å‹"""
        cmd = [sys.executable, 'src/training/train_lora.py']
        
        if self.test_mode:
            # æµ‹è¯•æ¨¡å¼ï¼šå¿«é€ŸéªŒè¯æµç¨‹
            cmd.extend([
                '--num-epochs', '1',
                '--batch-size', '2',
                '--gradient-accumulation-steps', '2',
                '--save-steps', '50',
                '--logging-steps', '5',
            ])
        
        self.run_command(cmd, "LoRAå¾®è°ƒè®­ç»ƒ")
    
    def run(self):
        """æ‰§è¡Œå®Œæ•´è®­ç»ƒæµç¨‹"""
        logger.info("="*70)
        logger.info("ğŸ¯ GISä»£ç ç”Ÿæˆæ¨¡å‹ - å¿«é€Ÿè®­ç»ƒ")
        logger.info("="*70)
        logger.info(f"æ¨¡å¼: {'æµ‹è¯•æ¨¡å¼ (å¿«é€ŸéªŒè¯)' if self.test_mode else 'å®Œæ•´è®­ç»ƒ'}")
        logger.info("="*70)
        
        # 1. æ£€æŸ¥ä¾èµ–
        self.check_dependencies()
        
        # 2. æ£€æŸ¥æ•°æ®
        self.check_data_files()
        
        # 3. å‡†å¤‡è®­ç»ƒæ•°æ®
        logger.info("\n" + "="*70)
        logger.info("æ­¥éª¤ 1/2: å‡†å¤‡è®­ç»ƒæ•°æ®")
        logger.info("="*70)
        self.prepare_training_data()
        
        # 4. è®­ç»ƒæ¨¡å‹
        logger.info("\n" + "="*70)
        logger.info("æ­¥éª¤ 2/2: è®­ç»ƒæ¨¡å‹")
        logger.info("="*70)
        self.train_model()
        
        # å®Œæˆ
        logger.info("\n" + "="*70)
        logger.info("ğŸ‰ è®­ç»ƒå®Œæˆï¼")
        logger.info("="*70)
        logger.info("ğŸ“¦ æ¨¡å‹ä½ç½®: models/qwen-gis-lora/")
        logger.info("ğŸ“Š è®­ç»ƒæ•°æ®: data/training/")
        logger.info("")
        logger.info("ä¸‹ä¸€æ­¥:")
        logger.info("  1. è¯„ä¼°æ¨¡å‹: python examples/evaluate_model.py")
        logger.info("  2. æµ‹è¯•æ¨ç†: python examples/demo_inference.py")
        logger.info("="*70)


def main():
    parser = argparse.ArgumentParser(description="å¿«é€Ÿè®­ç»ƒGISä»£ç ç”Ÿæˆæ¨¡å‹")
    parser.add_argument('--test', action='store_true',
                       help='æµ‹è¯•æ¨¡å¼ï¼ˆå°æ•°æ®é›†ï¼Œå¿«é€ŸéªŒè¯ï¼‰')
    parser.add_argument('--full', action='store_true',
                       help='å®Œæ•´è®­ç»ƒæ¨¡å¼')
    
    args = parser.parse_args()
    
    # é»˜è®¤ä½¿ç”¨æµ‹è¯•æ¨¡å¼
    test_mode = not args.full
    
    trainer = QuickTrainer(test_mode=test_mode)
    trainer.run()


if __name__ == "__main__":
    main()
