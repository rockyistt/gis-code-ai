"""
åŸºäºæ‚¨çš„å®é™…æ•°æ®çš„å®Œæ•´åå‘æ¨ç†ç¤ºä¾‹
å¯ä»¥ç›´æ¥è¿è¡Œï¼Œå±•ç¤ºä¸åŒæ–¹æ³•çš„æ•ˆæœå¯¹æ¯”
"""

import json
from pathlib import Path
from typing import Dict, List


class SimpleInferencer:
    """ç®€å•ä½†å®ç”¨çš„æ¨ç†å™¨ - ä¸éœ€è¦ä»»ä½•API"""
    
    def __init__(self):
        # æ“ä½œåŠ¨è¯æ˜ å°„
        self.action_verbs = {
            "Create": "Create",
            "Update": "Update", 
            "Delete": "Delete",
            "Open Object": "Open",
            "Open Object with ID": "Open",
            "Switch Spatial Context": "Switch to",
            "Verify Field": "Verify",
            "Select Tab": "Navigate to",
            "Click Oneshot Button": "Click",
            "Select first HV object": "Select",
            "Select second HV object": "Select",
            "Datamodel Check": "Perform consistency check on"
        }
        
        # æ¨¡å—æè¿°
        self.module_desc = {
            "Editor(s)": "editor",
            "Datamodel CRUD": "datamodel",
            "Tabs": "tab",
            "Buttons": "button",
            "Hierarchy Viewer": "hierarchy viewer",
            "Datamodel Consistency Check": "consistency check"
        }
    
    def clean_object_name(self, obj: str) -> str:
        """æ¸…ç†å¯¹è±¡åç§°"""
        # ç§»é™¤æ•°æ®åº“å‰ç¼€
        if obj.startswith(':'):
            obj = obj[1:]
        return obj
    
    def extract_key_fields(self, test_data: Dict) -> Dict:
        """æå–å…³é”®å­—æ®µ"""
        result = {}
        
        for section in ['create', 'update', 'editor']:
            if section in test_data and test_data[section]:
                data = test_data[section]
                
                # æŸ¥æ‰¾è‡ªå®šä¹‰å­—æ®µ
                for key, value in data.items():
                    if key.startswith('FLD_CSTM') and isinstance(value, dict):
                        # æå–æœ‰ç”¨çš„å­—æ®µ
                        if 'Spatial Context' in value:
                            result['spatial_context'] = value['Spatial Context']
                        if 'Station Nummer' in value:
                            result['station'] = value['Station Nummer']
                        
                        # è®¡ç®—éIDå­—æ®µæ•°é‡
                        non_id_fields = [k for k in value.keys() if k != 'ID' and not k.startswith('FLD')]
                        result['field_count'] = len(non_id_fields)
                        
                        # æå–å…³é”®å±æ€§ï¼ˆå‰3ä¸ªï¼‰
                        result['key_attributes'] = non_id_fields[:3]
        
        return result
    
    def infer_step_instruction(self, step: Dict) -> str:
        """ä¸ºå•ä¸ªæ­¥éª¤ç”ŸæˆæŒ‡ä»¤"""
        module = step.get('module', '')
        method = step.get('method', '')
        obj = self.clean_object_name(step.get('object', ''))
        database = step.get('database', '').replace(':', '')
        
        # è·å–åŠ¨ä½œåŠ¨è¯
        action = self.action_verbs.get(method, method)
        
        # æå–å…³é”®å­—æ®µ
        test_data = step.get('test_data', {})
        key_info = self.extract_key_fields(test_data)
        
        # æ„å»ºæŒ‡ä»¤
        if method == "Create":
            if key_info.get('field_count'):
                return f"{action} a new {obj} with {key_info['field_count']} specified attributes"
            else:
                return f"{action} a new {obj} object"
        
        elif method == "Update":
            return f"{action} the {obj} with modified values"
        
        elif method == "Delete":
            return f"{action} the {obj} object"
        
        elif method in ["Open Object", "Open Object with ID"]:
            if key_info.get('spatial_context'):
                return f"{action} {obj} in {key_info['spatial_context']} context"
            else:
                return f"{action} {obj} in the {database} dataset"
        
        elif method == "Switch Spatial Context":
            context = key_info.get('spatial_context', 'specified')
            return f"{action} {context} spatial context"
        
        elif method == "Select Tab":
            return f"{action} the {obj} tab"
        
        elif method == "Click Oneshot Button":
            return f"{action} the '{obj}' button"
        
        elif "Select" in method and "HV object" in method:
            position = "first" if "first" in method else "second"
            return f"{action} the {position} {obj} in hierarchy viewer"
        
        elif method == "Datamodel Check":
            return f"{action} {obj}"
        
        else:
            # é€šç”¨æ¨¡æ¿
            module_name = self.module_desc.get(module, module)
            return f"{action} {obj} in {module_name}"
    
    def infer_workflow_instruction(self, workflow: Dict) -> str:
        """ä¸ºæ•´ä¸ªå·¥ä½œæµç”ŸæˆæŒ‡ä»¤"""
        steps = workflow.get('steps', [])
        file_id = workflow.get('file_id', '')
        
        # åˆ†æå·¥ä½œæµæ¨¡å¼
        operations = {
            'create': [],
            'update': [],
            'delete': [],
            'navigation': []
        }
        
        for step in steps:
            method = step.get('method', '')
            obj = self.clean_object_name(step.get('object', ''))
            
            if method == 'Create':
                operations['create'].append(obj)
            elif method == 'Update':
                operations['update'].append(obj)
            elif method == 'Delete':
                operations['delete'].append(obj)
            elif method in ['Select Tab', 'Click Oneshot Button']:
                operations['navigation'].append(obj)
        
        # æ„å»ºæè¿°
        parts = []
        
        if operations['create']:
            unique_objects = list(set(operations['create']))
            if len(unique_objects) == 1:
                parts.append(f"create {unique_objects[0]}")
            else:
                parts.append(f"create multiple objects ({', '.join(unique_objects[:3])})")
        
        if operations['update']:
            parts.append("update their properties")
        
        if operations['delete']:
            parts.append("delete specified objects")
        
        # ç”Ÿæˆæœ€ç»ˆæè¿°
        if parts:
            action_desc = ", ".join(parts)
            return f"Test workflow to {action_desc} in the GIS system"
        else:
            return f"Test workflow for {file_id}: perform editor operations and navigation"
    
    def analyze_workflow_pattern(self, workflow: Dict) -> str:
        """åˆ†æå·¥ä½œæµæ¨¡å¼ç±»å‹"""
        steps = workflow.get('steps', [])
        methods = [step.get('method') for step in steps]
        
        # CRUDæ¨¡å¼
        has_create = 'Create' in methods
        has_update = 'Update' in methods
        has_delete = 'Delete' in methods
        
        if has_create and has_update and has_delete:
            return "Full CRUD test workflow"
        elif has_create:
            return "Object creation workflow"
        elif has_update:
            return "Object modification workflow"
        
        # å¯¼èˆªæ¨¡å¼
        nav_methods = ['Select Tab', 'Click Oneshot Button']
        if any(m in methods for m in nav_methods):
            return "Navigation and UI test workflow"
        
        return "General test workflow"


def demo_with_real_data():
    """ä½¿ç”¨çœŸå®æ•°æ®æ¼”ç¤º"""
    
    # è¯»å–ä¸€äº›çœŸå®æ•°æ®
    data_file = Path("data/processed/parsed_workflows.jsonl")
    
    if not data_file.exists():
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
        print("è¯·ç¡®ä¿å·²è¿è¡Œæ•°æ®å¤„ç†è„šæœ¬")
        return
    
    # åŠ è½½å‰3ä¸ªå·¥ä½œæµä½œä¸ºç¤ºä¾‹
    workflows = []
    with open(data_file, 'r', encoding='utf-8') as f:
        for i, line in enumerate(f):
            if i >= 3:  # åªå–å‰3ä¸ª
                break
            if line.strip():
                workflows.append(json.loads(line))
    
    print("="*70)
    print("ä»çœŸå®JSONåå‘æ¨ç†ç”¨æˆ·æŒ‡ä»¤ - æ¼”ç¤º")
    print("="*70)
    
    inferencer = SimpleInferencer()
    
    for wf_idx, workflow in enumerate(workflows, 1):
        print(f"\n{'='*70}")
        print(f"å·¥ä½œæµ #{wf_idx}: {workflow['file_id']}")
        print(f"é«˜è´¨é‡æ¨¡æ¿: {'âœ…' if workflow.get('is_high_quality') else 'âŒ'}")
        print(f"æ€»æ­¥éª¤æ•°: {workflow['total_steps']}")
        print(f"{'='*70}")
        
        # å·¥ä½œæµçº§åˆ«æŒ‡ä»¤
        workflow_instruction = inferencer.infer_workflow_instruction(workflow)
        pattern = inferencer.analyze_workflow_pattern(workflow)
        
        print(f"\nğŸ“‹ æ•´ä½“æè¿°:")
        print(f"   ç±»å‹: {pattern}")
        print(f"   æŒ‡ä»¤: {workflow_instruction}")
        
        # æ­¥éª¤çº§åˆ«æŒ‡ä»¤ï¼ˆåªæ˜¾ç¤ºå‰5æ­¥ï¼‰
        print(f"\nğŸ“ æ­¥éª¤è¯¦æƒ… (å‰5æ­¥):")
        for step in workflow['steps'][:5]:
            instruction = inferencer.infer_step_instruction(step)
            print(f"\n   æ­¥éª¤ {step['step_index']}:")
            print(f"   - æ¨¡å—: {step['module']}")
            print(f"   - æ–¹æ³•: {step['method']}")
            print(f"   - å¯¹è±¡: {step['object']}")
            print(f"   - æŒ‡ä»¤: {instruction}")
        
        if len(workflow['steps']) > 5:
            print(f"\n   ... è¿˜æœ‰ {len(workflow['steps']) - 5} ä¸ªæ­¥éª¤")
    
    print(f"\n{'='*70}")
    print("âœ… æ¼”ç¤ºå®Œæˆ!")
    print("="*70)
    
    # ç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“Š ç”Ÿæˆç»Ÿè®¡:")
    total_workflows = len(workflows)
    total_steps = sum(len(wf['steps']) for wf in workflows)
    print(f"   - å¤„ç†çš„å·¥ä½œæµ: {total_workflows}")
    print(f"   - ç”Ÿæˆçš„å·¥ä½œæµæŒ‡ä»¤: {total_workflows}")
    print(f"   - ç”Ÿæˆçš„æ­¥éª¤æŒ‡ä»¤: {total_steps}")
    print(f"\nğŸ’¡ æç¤º: è¿™ç§æ–¹æ³•ä¸éœ€è¦ä»»ä½•APIï¼Œå®Œå…¨ç¦»çº¿å¯ç”¨ï¼")


def generate_all_instructions():
    """ä¸ºæ‰€æœ‰å·¥ä½œæµç”ŸæˆæŒ‡ä»¤å¹¶ä¿å­˜"""
    
    input_file = Path("data/processed/parsed_workflows.jsonl")
    output_file = Path("data/processed/generated_instructions_simple.jsonl")
    
    if not input_file.exists():
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        return
    
    print("å¼€å§‹å¤„ç†æ‰€æœ‰å·¥ä½œæµ...")
    
    # åŠ è½½æ‰€æœ‰å·¥ä½œæµ
    workflows = []
    with open(input_file, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                workflows.append(json.loads(line))
    
    print(f"åŠ è½½äº† {len(workflows)} ä¸ªå·¥ä½œæµ")
    
    inferencer = SimpleInferencer()
    results = []
    
    # å¤„ç†æ¯ä¸ªå·¥ä½œæµ
    for i, workflow in enumerate(workflows):
        if (i + 1) % 100 == 0:
            print(f"è¿›åº¦: {i + 1}/{len(workflows)}")
        
        # ç”Ÿæˆå·¥ä½œæµçº§åˆ«æŒ‡ä»¤
        file_instruction = inferencer.infer_workflow_instruction(workflow)
        pattern = inferencer.analyze_workflow_pattern(workflow)
        
        # ç”Ÿæˆæ­¥éª¤çº§åˆ«æŒ‡ä»¤
        step_instructions = []
        for step in workflow['steps']:
            step_inst = inferencer.infer_step_instruction(step)
            step_instructions.append({
                "step_index": step['step_index'],
                "module": step['module'],
                "method": step['method'],
                "object": step['object'],
                "instruction": step_inst
            })
        
        # ä¿å­˜ç»“æœ
        result = {
            "file_id": workflow['file_id'],
            "is_high_quality": workflow.get('is_high_quality', False),
            "workflow_pattern": pattern,
            "file_level_instruction": file_instruction,
            "step_level_instructions": step_instructions
        }
        results.append(result)
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    with open(output_file, 'w', encoding='utf-8') as f:
        for result in results:
            f.write(json.dumps(result, ensure_ascii=False) + '\n')
    
    print(f"\nâœ… å®Œæˆ!")
    print(f"   - å¤„ç†çš„å·¥ä½œæµ: {len(workflows)}")
    print(f"   - ç”Ÿæˆçš„å·¥ä½œæµæŒ‡ä»¤: {len(results)}")
    print(f"   - æ€»æ­¥éª¤æŒ‡ä»¤: {sum(len(r['step_level_instructions']) for r in results)}")
    print(f"   - è¾“å‡ºæ–‡ä»¶: {output_file}")


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "--all":
        # ç”Ÿæˆæ‰€æœ‰æŒ‡ä»¤
        generate_all_instructions()
    else:
        # æ¼”ç¤ºæ¨¡å¼
        demo_with_real_data()
        
        print("\n" + "="*70)
        print("ğŸ’¡ æç¤º:")
        print("   - è¿è¡Œ 'python examples/demo_inference.py' æŸ¥çœ‹æ¼”ç¤º")
        print("   - è¿è¡Œ 'python examples/demo_inference.py --all' å¤„ç†æ‰€æœ‰æ•°æ®")
        print("="*70)
